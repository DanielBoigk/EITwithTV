{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a2562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Code/Julia/FerriteStuff/Notebooks/Github/EnvFerrite`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"EnvFerrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce44614",
   "metadata": {},
   "source": [
    "# Electrical Impedance Tomography with TV Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f621f58",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this example we give a basic implementation of of the real valued Calderon problem relevant to Electrical Impedance Tomography. We will generate data and afterwards solve the inverse problem with a numerical solver and implement TV regularization.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc6c5a",
   "metadata": {},
   "source": [
    "### Forward EIT:\n",
    "Given a conductivity $\\gamma: \\Omega\\subset\\mathbb{R}^2 \\rightarrow \\mathbb{R}_{+}$ our solution $u\\in H^1(\\Omega,\\mathbb{R}^2)$ (2D case) has to confirm to the equation:\n",
    "\n",
    "\n",
    "$$ \\nabla \\cdot(\\gamma\\nabla u) = 0 \\quad \\forall x \\in \\Omega $$\n",
    "\n",
    "For that equation we will choose a set of electrical current patterns \n",
    "\n",
    "$$ g_1, ..., g_n \\in H^{-\\frac{1}{2}}(\\partial \\Omega, \\mathbb{R}) $$\n",
    "\n",
    "such that:  \n",
    "\n",
    "$$ \\int_{\\partial\\Omega}g_i \\, d\\partial\\Omega = 0 $$\n",
    "\n",
    "to inject into the material via Neumann boundary conditions:\n",
    "\n",
    "$$ \\gamma\\frac{\\partial u_i}{\\partial n} =g_i \\quad \\forall x \\in \\partial\\Omega $$\n",
    "\n",
    "In order to get the corresponding voltages \n",
    "$$ f_1, ..., f_n \\in H^{\\frac{1}{2}}(\\partial \\Omega, \\mathbb{R}) $$\n",
    "we will measure the corresponding voltage as:\n",
    "$$ f_i := u_i|_{\\partial\\Omega} $$\n",
    "\n",
    "with those boundary pairs $ (f_1,g_1), ... , (f_n,g_n) $ we now have an approximation of the Dirichlet to Neumann map:\n",
    "$$ \\Lambda_\\gamma: H^{\\frac{1}{2}}(\\partial \\Omega)\\rightarrow H^{-\\frac{1}{2}}(\\partial \\Omega) $$\n",
    "This is called forward EIT since we just approximated the map:\n",
    "$$ \\gamma \\rightarrow  \\Lambda_\\gamma $$\n",
    "\n",
    "However real Electrical Impedance Tomography requires us to solve an **inverse Problem** where we have to reconstruct:\n",
    "$$ \\Lambda_\\gamma \\rightarrow  \\gamma $$\n",
    "for our approximation of $\\Lambda_\\gamma$ given by voltage-current boundary pairs $(f_i,g_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f0406",
   "metadata": {},
   "source": [
    "### Weak formulation\n",
    "Given the strong formulation:\n",
    "$$ \\nabla \\cdot(\\gamma\\nabla u) = 0 \\quad \\text{with Neumann BC:}\\quad \\gamma\\frac{\\partial u}{\\partial n} = g $$\n",
    "\n",
    "The weak formulation is:\n",
    "$$ \\int\\limits_\\Omega \\gamma \\nabla(u)\\cdot\\nabla(v) \\, d \\Omega = \\int\\limits_{\\partial\\Omega} g \\,v \\,d\\partial\\Omega  \\quad \\forall v\\in H^1(\\Omega)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de196c6",
   "metadata": {},
   "source": [
    "### Inverse EIT\n",
    "We will use $\\gamma$ to refer to the true underlying conductivity and $\\sigma$ for our current conductivity guess.\n",
    "We will choose the simplest minimization functional for optimization:\n",
    "$$ J_i(u_i,\\sigma) = \\| f_i- u_i\\|^2_{\\mathcal{L}^2(\\partial\\Omega)} = \\int_{\\partial\\Omega}(f_i-u_i)^2 \\,d\\partial\\Omega $$\n",
    "In theory however we can plug in another metric or pseudo-metric like Wasserstein-distance or Spetral distance as mesure of distance between $f_i$ und $u_i$.\n",
    "Such that our problem becomes:\n",
    "$$ \\underset{\\sigma}{\\min} \\sum\\limits_{i=1}^n J_i(u_i,\\sigma) $$\n",
    "such that:\n",
    "$$ \\nabla u_i\\cdot(\\sigma\\nabla u_i) = 0\\quad  \\text{and Neumann BC}\\quad \\sigma\\frac{\\partial u_i}{\\partial n} = g_i \\quad \\forall i\\in\\{1, ...,n\\}$$\n",
    "Given the problem our lagrangian becomes:\n",
    "$$ \\mathcal{L}(\\sigma, u, \\lambda) = \\sum\\limits_{i=1}^n\\left( J_i(u_i,\\sigma) + \\langle \\lambda_i, \\nabla\\cdot(\\sigma\\nabla u_i) \\rangle_{\\mathcal{L}^2(\\Omega)}   \\right) $$\n",
    "\n",
    "from this we will use [Adjoint state methods](https://en.wikipedia.org/wiki/Adjoint_state_method#General_case) to calculate the gradient.\n",
    "Without stating any of the steps of the derivation we end up with:\n",
    "- State Equation (Variation with $\\delta_\\lambda$)\n",
    "$$ \\nabla \\cdot(\\sigma\\nabla u_i) = 0\\quad  \\text{with Neumann BC}\\quad \\sigma\\frac{\\partial u_i}{\\partial n} = g_i$$\n",
    "\n",
    "- Adjoint Equation (Variation with $\\delta_u$)\n",
    "$$ \\nabla \\cdot(\\sigma\\nabla\\lambda_i) = 0\\quad  \\text{with Neumann BC}\\quad \\sigma\\frac{\\partial \\lambda_i}{\\partial n} = 2(u_i-f_i)$$\n",
    "- Functional Derivative (Variation with $\\delta_\\sigma$)\n",
    "$$ \\delta_i\\sigma = -\\nabla u_i \\cdot \\nabla \\lambda_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a63d6ec",
   "metadata": {},
   "source": [
    "#### Total Variation (TV) regularization\n",
    "for real world examples and numerical stability we have to assume that our system contains some noise, like $f = f_{true} + \\epsilon$. Since the inverse EIT problem is highly ill conditioned we have to consider regularization.\n",
    "\n",
    "\n",
    "Because $|\\nabla\\sigma|^2$ is non-differentiable when $\\nabla\\sigma=0$, we use\n",
    "$$\n",
    "\\mathcal{R}_{TV}(\\sigma) = \\int_\\Omega \\sqrt{|\\nabla\\sigma|^2+\\eta}\\, d\\Omega,\n",
    "$$\n",
    "and the gradient:\n",
    "$$ \\delta_\\sigma\\mathcal{R}= -\\nabla\\cdot \\left(   \\frac{\\nabla\\sigma}{\\sqrt{|\\nabla \\sigma|^2+ \\eta}} \\right) $$\n",
    "with a small $\\eta$ to revent division by zero.\n",
    "This is a $L^2$ projection that requires us to sove the weak form.\n",
    "##### Weak formulation of TV Regularizer:\n",
    "$$ \\int_\\Omega wv \\,d\\Omega = \\int_\\Omega \\frac{\\nabla(\\sigma)}{\\sqrt{|\\nabla\\sigma|^2+\\eta}}\\cdot\\nabla(v)\\, d\\Omega \\quad \\forall v\\in FESpace$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf00a9",
   "metadata": {},
   "source": [
    "### Full reconstruction Algorithm (Conceptual)\n",
    "+ Preallocate Massmatrix M and L^2 projector (Cholesky factorization)\n",
    "+ Start with conductivity guess $\\sigma_0$ (In our case: $\\sigma_0(x) = 1.0$)\n",
    "+ Preallocate & initialize Conjugate Gradient(CG) solver for $u_1, ...,u_n.\\lambda_1,.., \\lambda_n,w$.\n",
    "+ Repeat till tolerance is reached or other stopping condition:\n",
    "    + From $\\sigma_t$ assemble stiffness matrix $K_{\\sigma_t}$\n",
    "    + for all $i = 1, ...,n$ (in parallel)\n",
    "        + Calculate $u_i$ (State equation) as well as the $\\mathcal{L}^2(\\partial\\Omega)$ error: $\\delta u_i$\n",
    "        + Calculate $\\lambda_i$ (Adjoint equation)\n",
    "        + Calculate $\\delta\\sigma_i$ (Functional derivative)\n",
    "    + Calculate TV Regularization gradient and error.\n",
    "    + Update $\\sigma_{t+1} = \\sigma_t +\\beta\\, \\delta_{TV}\\sigma + \\sum_{i=1}^n \\alpha_i\\,\\delta_i\\sigma $ (with Gauss-Newton with Levenberg-Marquardt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b89dc",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "### Preliminaries\n",
    "Obvious Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa44a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Ferrite\n",
    "using SparseArrays\n",
    "using LinearAlgebra\n",
    "using Revise\n",
    "using Interpolations\n",
    "using Plots\n",
    "using Statistics\n",
    "using IterativeSolvers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33323b7",
   "metadata": {},
   "source": [
    "For simplicity we will use a quadratic grid with quadrilateral elements. We are using Quadrilaterals for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9a883c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = generate_grid(Quadrilateral, (32, 32));\n",
    "dim = Ferrite.getspatialdim(grid)\n",
    "order = 1\n",
    "\n",
    "\n",
    "ip = Lagrange{RefQuadrilateral, order}()\n",
    "qr = QuadratureRule{RefQuadrilateral}(2)\n",
    "qr_face = FacetQuadratureRule{RefQuadrilateral}(2)\n",
    "cellvalues = CellValues(qr, ip)\n",
    "facetvalues = FacetValues(qr_face, ip)\n",
    "\n",
    "dh = DofHandler(grid)\n",
    "add!(dh, :u, ip)\n",
    "close!(dh)\n",
    "\n",
    "\n",
    "\n",
    "∂Ω = union(getfacetset.((grid,), [\"left\", \"top\", \"right\", \"bottom\"])...)\n",
    "length(∂Ω)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30d783",
   "metadata": {},
   "source": [
    "For later use we will assemble and cholesky decompose the mass matrix once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f950d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sparse([1, 2, 3, 4, 1, 2, 3, 4, 5, 6  …  1054, 1055, 1056, 1087, 1088, 1089, 1055, 1056, 1088, 1089], [1, 1, 1, 1, 2, 2, 2, 2, 2, 2  …  1088, 1088, 1088, 1088, 1088, 1088, 1089, 1089, 1089, 1089], [0.0004340277777777777, 0.00021701388888888885, 0.00010850694444444441, 0.00021701388888888882, 0.00021701388888888885, 0.0008680555555555555, 0.0004340277777777777, 0.00010850694444444441, 0.00021701388888888893, 0.00010850694444444444  …  0.00010850694444444444, 0.0004340277777777777, 0.00010850694444444441, 0.00021701388888888882, 0.0008680555555555553, 0.00021701388888888882, 0.00010850694444444441, 0.00021701388888888882, 0.00021701388888888882, 0.00043402777777777765], 1089, 1089), SparseArrays.CHOLMOD.Factor{Float64, Int64}\n",
       "type:    LLt\n",
       "method:  simplicial\n",
       "maxnnz:  20895\n",
       "nnz:     20895\n",
       "success: true\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is supposed to be: ∫(u*v)dΩ\n",
    "function assemble_M(cellvalues::CellValues,dh::DofHandler)\n",
    "    M = allocate_matrix(dh)\n",
    "    n_basefuncs = getnbasefunctions(cellvalues)\n",
    "    Me = zeros(n_basefuncs, n_basefuncs)\n",
    "    assembler = start_assemble(M)\n",
    "    for cell in CellIterator(dh)\n",
    "        fill!(Me, 0)\n",
    "        reinit!(cellvalues, cell)\n",
    "        for q_point in 1:getnquadpoints(cellvalues)\n",
    "            dΩ = getdetJdV(cellvalues, q_point)      \n",
    "            for i in 1:n_basefuncs\n",
    "                φᵢ = shape_value(cellvalues, q_point, i)\n",
    "                for j in 1:n_basefuncs\n",
    "                    φⱼ = shape_value(cellvalues, q_point, j)\n",
    "                    Me[i,j] += φᵢ * φⱼ * dΩ\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        assemble!(assembler, celldofs(cell), Me)\n",
    "    end\n",
    "    return M, cholesky(M)\n",
    "end   \n",
    "\n",
    "M, MC = assemble_M(cellvalues,dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0369c0",
   "metadata": {},
   "source": [
    "Furthermore we want to know which entries of the force vector correspond to the boundary:\n",
    "We will get:\n",
    "- the count of nonzero entries in the force vector\n",
    "- the position of non zero entries\n",
    "- a function \"up\" to cast a vector of length of boundary dofs into the length of the force vector\n",
    "- a function \"down\" to cast a vector into the length of the dofs of the force vector that lay on the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1acc5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function produce_nonzero_positions(v, atol=1e-8, rtol=1e-5)\n",
    "    approx_zero(x; atol=atol, rtol=rtol) = isapprox(x, 0; atol=atol, rtol=rtol)\n",
    "    non_zero_count = count(x -> !approx_zero(x), v)\n",
    "    non_zero_positions = zeros(Int, non_zero_count)\n",
    "    non_zero_indices = findall(x -> !approx_zero(x), v)\n",
    "    g_down = (x) -> x[non_zero_indices]\n",
    "    g_up = (x) -> begin\n",
    "        v = zeros(eltype(x), length(v))\n",
    "        v[non_zero_indices] = x\n",
    "        return v\n",
    "    end\n",
    "    return non_zero_count, non_zero_positions, g_down, g_up\n",
    "end\n",
    "function produce_nonzero_positions(facetvalues::FacetValues, dh::DofHandler, ∂Ω)\n",
    "    f = zeros(ndofs(dh))\n",
    "        for facet in FacetIterator(dh, ∂Ω)\n",
    "        fe = zeros(ndofs_per_cell(dh))\n",
    "        reinit!(facetvalues, facet)\n",
    "        for q_point in 1:getnquadpoints(facetvalues)\n",
    "            dΓ = getdetJdV(facetvalues, q_point)            \n",
    "            for i in 1:getnbasefunctions(facetvalues)\n",
    "                δu = shape_value(facetvalues, q_point, i)\n",
    "                fe[i] += δu * dΓ\n",
    "            end\n",
    "        end\n",
    "        assemble!(f, celldofs(facet), fe)\n",
    "    end\n",
    "     nzc, nzpos, g_down, g_up = produce_nonzero_positions(f)\n",
    "     return  nzc, nzpos, g_down, g_up, f\n",
    "end\n",
    "\n",
    "nzc,nzpos, down, up = produce_nonzero_positions(facetvalues, dh,∂Ω)\n",
    "@assert nzc == length(∂Ω)  # This is not true in Gridap.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9909e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity check:\n",
    "# I have never questioned the assumption that up∘down == id and down∘up == id. Maybe I should check this.\n",
    "test_vec = [i for i in 1:nzc]\n",
    "@assert down(up(test_vec)) == test_vec\n",
    "@assert up(down(up(test_vec))) == up(test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704c0e9",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724653f",
   "metadata": {},
   "source": [
    "Now we will make up some conductivity. As well as some current patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a32db90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#22 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conductivity  = (x) -> 1.1 + sin(x[1]) * cos(x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5ee93",
   "metadata": {},
   "source": [
    "For later we want to project that function unto Q1 FE space for that we want to assemble the coefficients in the FESpace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741f5446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089-element Vector{Float64}:\n",
       " 0.6450535642159253\n",
       " 0.6641859150714466\n",
       " 0.6226468097664015\n",
       " 0.601690881462597\n",
       " 0.685021948586164\n",
       " 0.645468805231958\n",
       " 0.707477970024696\n",
       " 0.6700651958589253\n",
       " 0.7314669135515499\n",
       " 0.6963406172344299\n",
       " ⋮\n",
       " 1.3592050021692093\n",
       " 1.3883340781632245\n",
       " 1.416337215072183\n",
       " 1.4431050644646248\n",
       " 1.4685330864484494\n",
       " 1.492522029975305\n",
       " 1.5149780514138347\n",
       " 1.5358140849285546\n",
       " 1.5549464357840737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function assemble_function_vector(cellvalues::CellValues, dh::DofHandler, f, M_cholesky)\n",
    "    F = zeros(ndofs(dh))\n",
    "    n_basefuncs = getnbasefunctions(cellvalues)\n",
    "    Fe = zeros(n_basefuncs)\n",
    "    cdofs = zeros(Int, n_basefuncs)\n",
    "\n",
    "    for cell in CellIterator(dh)\n",
    "        fill!(Fe, 0.0)\n",
    "        reinit!(cellvalues, cell)\n",
    "        coords = getcoordinates(cell)\n",
    "        cdofs = celldofs(cell)\n",
    "        for q in 1:getnquadpoints(cellvalues)\n",
    "            x_q = spatial_coordinate(cellvalues, q, coords)\n",
    "            f_val = f(x_q)\n",
    "            dΩ = getdetJdV(cellvalues, q)\n",
    "\n",
    "            for i in 1:n_basefuncs\n",
    "                Fe[i] += f_val * shape_value(cellvalues, q, i) * dΩ\n",
    "            end\n",
    "        end  \n",
    "        assemble!(F, cdofs,Fe)\n",
    "    end\n",
    "    return M_cholesky \\ F\n",
    "end\n",
    "cond_vec = assemble_function_vector(cellvalues, dh, conductivity, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aee32e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089×1089 SparseMatrixCSC{Float64, Int64} with 9409 stored entries:\n",
       "⎡⠻⣦⡸⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤\n",
       "⎢⠲⢮⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣟⣽⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣟⣽⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣟⣽⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣟⣽⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⎥\n",
       "⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function assembles the stiffness matrix from a given vector.\n",
    "# Hopefully this is: ∫(γ * ∇(u)⋅∇(v))dΩ \n",
    "function assemble_K(cellvalues::CellValues, dh::DofHandler, γ::AbstractVector)\n",
    "    K = allocate_matrix(dh)\n",
    "    n_basefuncs = getnbasefunctions(cellvalues)\n",
    "    Ke = zeros(n_basefuncs, n_basefuncs)\n",
    "    assembler = start_assemble(K)\n",
    "    for cell in CellIterator(dh)\n",
    "        fill!(Ke, 0)\n",
    "        reinit!(cellvalues, cell)\n",
    "        for q_point in 1:getnquadpoints(cellvalues)\n",
    "            dΩ = getdetJdV(cellvalues, q_point)\n",
    "            γe = γ[celldofs(cell)] # (Edit) Could be done more efficiently by copying into preallocated array\n",
    "            σ = function_value(cellvalues, q_point, γe)\n",
    "            for i in 1:n_basefuncs\n",
    "                ∇v = shape_gradient(cellvalues, q_point, i)\n",
    "                #u = shape_value(cellvalues, q_point, i)\n",
    "                for j in 1:n_basefuncs\n",
    "                    ∇u = shape_gradient(cellvalues, q_point, j)\n",
    "                    Ke[i, j] += σ* (∇v ⋅ ∇u) * dΩ\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        assemble!(assembler, celldofs(cell), Ke)\n",
    "    end\n",
    "    return K\n",
    "end\n",
    "\n",
    "K_from_vec = assemble_K(cellvalues, dh,cond_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee77cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseArrays.UMFPACK.UmfpackLU{Float64, Int64}\n",
       "L factor:\n",
       "1089×1089 SparseMatrixCSC{Float64, Int64} with 20895 stored entries:\n",
       "⎡⠳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤\n",
       "⎢⠴⠿⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠤⠀⠀⠿⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⣐⣳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠨⣵⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⠒⠛⠛⠛⢳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⠐⠶⠀⠐⠶⠿⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠚⢳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⠛⢳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣠⣤⢤⣤⣴⢾⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠉⠉⠀⠀⠀⠀⠉⠉⣳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢨⡷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠱⣄⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠴⠾⠷⣄⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣠⡄⣤⣤⡴⢶⣾⣷⣄⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⢠⣄⣴⠒⠆⠀⠀⠰⣤⣴⣏⢛⠀⠀⠀⠐⠒⠒⢚⣯⢩⠒⠛⠃⠀⠀⠐⠶⢿⣷⣄⠀⠀⎥\n",
       "⎣⣲⠆⣴⡏⠛⣧⣴⢾⡳⣿⠀⠉⠁⠀⠉⠛⠛⠧⠠⠤⠀⣤⣤⠀⠀⣤⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⣼⣿⣷⣄⎦\n",
       "U factor:\n",
       "1089×1089 SparseMatrixCSC{Float64, Int64} with 20895 stored entries:\n",
       "⎡⠙⢦⣴⡇⠀⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⠞⎤\n",
       "⎢⠀⠀⠙⢧⣤⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡴⠿⎥\n",
       "⎢⠀⠀⠀⠀⠙⢧⢀⢠⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠿⣤⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠙⢾⡀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣰⣟⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠑⢿⣀⡀⠀⠀⢀⠀⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣽⣽⣮⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢧⡀⠀⣼⠀⢰⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⠄⡄⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⣿⠀⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠁⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢶⣼⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⣦⣧⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢧⣠⠀⠀⠀⠀⠀⠀⢠⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⡴⢿⠿⡄⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢶⣀⡀⠀⠀⠀⣾⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠛⠐⠀⡆⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢧⣴⠀⠀⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣤⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢶⣰⣟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⠀⠀⠛⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⣸⢀⠀⣤⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢾⡀⣀⡀⠀⠀⠀⠀⣸⡏⣛⠀⠉⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢯⡇⠀⠀⠀⠀⣭⣼⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⢦⣰⡇⢀⡿⠉⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢧⣸⣷⢀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⣼⣇⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⣶⣿⎥\n",
       "⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢿⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is matrix assembly on a function. How do I do it if the conductivity is given as a coefficient vector for Q1 FE Space?\n",
    "# Hopefully this is: ∫(γ * ∇(u)⋅∇(v))dΩ \n",
    "function assemble_K(cellvalues::CellValues, dh::DofHandler, γ)\n",
    "    K = allocate_matrix(dh)\n",
    "    n_basefuncs = getnbasefunctions(cellvalues)\n",
    "    Ke = zeros(n_basefuncs, n_basefuncs)\n",
    "    assembler = start_assemble(K)\n",
    "    for cell in CellIterator(dh)\n",
    "        fill!(Ke, 0)\n",
    "        reinit!(cellvalues, cell)\n",
    "        for q in 1:getnquadpoints(cellvalues)\n",
    "            dΩ = getdetJdV(cellvalues, q)\n",
    "            x = spatial_coordinate(cellvalues, q, getcoordinates(cell))\n",
    "            σ = γ(x)\n",
    "            for i in 1:n_basefuncs\n",
    "                ∇v = shape_gradient(cellvalues, q, i)\n",
    "                for j in 1:n_basefuncs\n",
    "                    ∇u = shape_gradient(cellvalues, q, j)\n",
    "                    Ke[i, j] += σ * (∇v ⋅ ∇u) * dΩ\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        assemble!(assembler, celldofs(cell), Ke)\n",
    "    end\n",
    "    return K\n",
    "end\n",
    "\n",
    "K_true = assemble_K(cellvalues, dh, conductivity)\n",
    "K_true_LU = lu(K_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb7d5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: (positive semidefinite self adjoint stiffness matrix)\n",
    "@assert K_true == K_true'  # Not true in Gridap.jl\n",
    "if ndofs(dh) < 500\n",
    "    K_dense = Matrix(K_true)\n",
    "    eig_min = minimum(eigvals(K_dense))\n",
    "    @assert eig_min > -1e-14\n",
    "    print(\"Smallest eigenvalue: \", eig_min)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8ad31",
   "metadata": {},
   "source": [
    "Now we generate current patterns: We assume one current source and one current sink. Important is that it sums of to zero.\n",
    "We generate the right hand side force vectors $g_1, ... g_n$ as an Matrix G and calculate $f_1, ..., f_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ba150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128×8128 Matrix{Float64}:\n",
       "  2.28031     2.25774       2.8858     …   0.00896351   0.00471518\n",
       " -0.822377    0.128708      0.503204       0.00896068   0.00471448\n",
       "  0.15127    -0.907189      0.708219       0.00896638   0.0047159\n",
       " -0.102286    0.0801673    -1.03945        0.00895235   0.00471241\n",
       " -0.0645602   0.030441     -0.242412       0.00893867   0.00470901\n",
       " -0.0399858   0.0134256    -0.147098   …   0.00891984   0.00470433\n",
       " -0.0299563   0.00458881   -0.0979698      0.00889602   0.0046984\n",
       " -0.0244935  -0.000326226  -0.074219       0.00886739   0.00469129\n",
       " -0.0212772  -0.00332372   -0.0605148      0.00883415   0.00468302\n",
       " -0.0192336  -0.00526549   -0.0519835      0.0087965    0.00467366\n",
       "  ⋮                                    ⋱               \n",
       " -0.0134128  -0.0109905    -0.0283843      0.0240971    0.00839202\n",
       " -0.013424   -0.0109791    -0.0284286  …   0.0284299    0.00941065\n",
       " -0.0134336  -0.0109693    -0.0284667      0.0352115    0.0109726\n",
       " -0.0134417  -0.0109611    -0.0284985      0.0466772    0.0135594\n",
       " -0.0134482  -0.0109545    -0.0285243      0.0698071    0.0181989\n",
       " -0.0134532  -0.0109494    -0.0285442      0.113926     0.0292619\n",
       " -0.0134568  -0.0109458    -0.0285583  …   0.470987     0.0462862\n",
       " -0.0134589  -0.0109436    -0.0285667     -0.187214     0.353831\n",
       " -0.0134596  -0.0109429    -0.0285695     -1.15553     -0.922032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_modes = Int64((nzc^2-nzc)//2)\n",
    "G_small = zeros(nzc,num_modes)\n",
    "G = zeros(ndofs(dh),num_modes)\n",
    "k = 1\n",
    "for i in 1:(nzc-1)\n",
    "    for j in i+1:nzc\n",
    "        G_small[i,k] = 1.0\n",
    "        G_small[j,k] = -1.0\n",
    "        G[:,k] = up(G_small[:,k])\n",
    "        k += 1\n",
    "    end\n",
    "end\n",
    "F_big = K_true_LU \\ G\n",
    "F = zeros(nzc,num_modes)\n",
    "k = 1\n",
    "for i in 1:(nzc-1)\n",
    "    for j in i+1:nzc\n",
    "        F[:,k] = down(F_big[:,k])\n",
    "        k += 1\n",
    "    end\n",
    "end\n",
    "col_means = mean(F, dims=1)\n",
    "F .-= col_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73781c70",
   "metadata": {},
   "source": [
    "To be realistic we will add some noise:\n",
    "We have to ensure that our noise has mean zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be5718f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_zero_noise (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function mean_zero_noise(n::Int64, σ::Float64)\n",
    "    out = σ * randn(n)\n",
    "    mean = Statistics.mean(out)\n",
    "    out .- mean\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc589a66",
   "metadata": {},
   "source": [
    "To simplify things we can also do SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec45d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement SVD here later\n",
    "# reduce the number of modes according to used SVD modes\n",
    "function do_svd(F,G)\n",
    "    Λ = F * G'\n",
    "    num_modes = (size(Λ, 1) - 1)\n",
    "    V,Σ,U = svd(Λ)\n",
    "    U = U[:,1:num_modes]\n",
    "    V = V[:,1:num_modes]\n",
    "    col_means = mean(U, dims=1)\n",
    "    U .-= col_means\n",
    "    col_means = mean(V, dims=1)\n",
    "    V .-= col_means\n",
    "    # Not unimportant:\n",
    "    V = V * diagm(Σ[1:num_modes]) \n",
    "    return V, Σ, U, Λ, num_modes\n",
    "end\n",
    "F, Σ, G_small, Λ, num_modes = do_svd(F,G_small)\n",
    "# Apply singular Values:\n",
    "G = zeros(ndofs(dh),num_modes)\n",
    "F_big = copy(G)\n",
    "for i in 1:num_modes\n",
    "    G[:,i] = up(G_small[:,i])\n",
    "    F_big[:,i] = up(F[:,i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c3a036",
   "metadata": {},
   "source": [
    "now that we have done SVD on the original choice of modes we have \n",
    "- Truncation of SVD modes, thus regularization\n",
    "- Averaging of noise over multiple measurements\n",
    "- Elimination of any unncessary number of nodes we choose before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6dd1a",
   "metadata": {},
   "source": [
    "Here we define a struct where we save and preallocate all the necessary information for the solver step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "590b664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f965019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of Matrix difference: 8.536307354525758e-6\n",
      "norm of difference of first SVD mode: 12.060954332454587\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "AssertionError: vector_norm < 10.0",
     "output_type": "error",
     "traceback": [
      "AssertionError: vector_norm < 10.0\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X46sZmlsZQ==.jl:11"
     ]
    }
   ],
   "source": [
    "# Implement a sanity check if the two matrices assembled from the function and the vector are roughly the same (use relatively coarse ≈ )\n",
    "Matrix_norm = norm(K_from_vec - K_true)\n",
    "println(\"Norm of Matrix difference: \",Matrix_norm)\n",
    "@assert Matrix_norm < 20.0\n",
    "\n",
    "g_test = G[:,1]\n",
    "f_test_true = K_true \\ g_test\n",
    "f_test_vec = K_from_vec \\g_test\n",
    "vector_norm = norm(f_test_true - f_test_vec)\n",
    "println(\"norm of difference of first SVD mode: \" ,vector_norm)\n",
    "@assert vector_norm < 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "059522f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct EITMode\n",
    "    u::AbstractVector\n",
    "    λ::AbstractVector\n",
    "    δσ::AbstractVector\n",
    "    f::AbstractVector\n",
    "    g::AbstractVector\n",
    "    rhs::AbstractVector\n",
    "    error::Float64\n",
    "    length::Int64\n",
    "    m::Int64\n",
    "end\n",
    "function EITMode(g::AbstractVector, f::AbstractVector)\n",
    "    L = length(g)\n",
    "    M = length(f)\n",
    "    return EITMode(zeros(L), zeros(L), zeros(L), f, g, zeros(L), 0.0, L, M)\n",
    "end\n",
    "mode_dict = Dict{Int64,EITMode}()\n",
    "for i in 1:num_modes\n",
    "    mode_dict[i] = EITMode(G[:,i],F[:,i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c2f19",
   "metadata": {},
   "source": [
    "### Solving EIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cd183",
   "metadata": {},
   "source": [
    "We will now assume a starting conductivity guess $\\sigma_0(x) = 1.0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "180dc966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#24 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "σ₀ = (x) -> 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc5166",
   "metadata": {},
   "source": [
    "We would prefer to save $\\sigma$ as a vector for use in FEM and also have a method to export each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "831b2fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089-element Vector{Float64}:\n",
       " 0.9999999999999998\n",
       " 1.0\n",
       " 0.9999999999999996\n",
       " 1.0000000000000002\n",
       " 0.9999999999999989\n",
       " 1.0000000000000007\n",
       " 1.0000000000000002\n",
       " 0.9999999999999992\n",
       " 0.9999999999999996\n",
       " 1.0000000000000009\n",
       " ⋮\n",
       " 1.0\n",
       " 1.0000000000000004\n",
       " 1.0\n",
       " 1.0000000000000009\n",
       " 0.9999999999999997\n",
       " 1.0000000000000007\n",
       " 0.9999999999999998\n",
       " 1.0000000000000002\n",
       " 0.9999999999999997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Project function here: \n",
    "σ = assemble_function_vector(cellvalues,dh, σ₀, MC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37970b5d",
   "metadata": {},
   "source": [
    "A prerequisite is that we can calculate the bilinear map: $\\nabla(u)\\cdot\\nabla(\\lambda)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f9e1067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_bilinear_map! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assemble right-hand side for the projection of ∇(u) ⋅ ∇(λ) onto the FE space.\n",
    "# This computes rhs_i = ∫ (∇u ⋅ ∇λ) ϕ_i dΩ for each test function ϕ_i.\n",
    "# Assuming u and λ are scalar fields in the same FE space.\n",
    "# cellvalues should be CellScalarValues(qr, ip) where qr is QuadratureRule, ip is Interpolation.\n",
    "function calculate_bilinear_map(a::AbstractVector, b::AbstractVector, cellvalues::CellValues, dh::DofHandler, M_cholesky)\n",
    "    n = ndofs(dh)\n",
    "    rhs = zeros(n)\n",
    "    n_basefuncs = getnbasefunctions(cellvalues)\n",
    "    qpoints = getnquadpoints(cellvalues)\n",
    "    re = zeros(n_basefuncs)\n",
    "    \n",
    "    for cell in CellIterator(dh)\n",
    "        dofs = celldofs(cell)\n",
    "        reinit!(cellvalues, cell)\n",
    "        fill!(re, 0.0)\n",
    "        \n",
    "        ae = a[dofs]\n",
    "        be = b[dofs]\n",
    "        \n",
    "        for q in 1:qpoints\n",
    "            dΩ = getdetJdV(cellvalues, q)\n",
    "            \n",
    "            ∇a_q = zero(Vec{2,Float64})\n",
    "            ∇b_q = zero(Vec{2,Float64})\n",
    "            \n",
    "            for j in 1:n_basefuncs\n",
    "                ∇ϕⱼ = shape_gradient(cellvalues, q, j)\n",
    "                ∇a_q += ae[j] * ∇ϕⱼ\n",
    "                ∇b_q += be[j] * ∇ϕⱼ\n",
    "            end\n",
    "            \n",
    "            grad_dot_product = ∇a_q ⋅ ∇b_q\n",
    "            \n",
    "            for i in 1:n_basefuncs\n",
    "                ϕᵢ = shape_value(cellvalues, q, i)\n",
    "                re[i] += grad_dot_product * ϕᵢ * dΩ\n",
    "            end\n",
    "        end\n",
    "        assemble!(rhs, dofs, re)\n",
    "    end\n",
    "    \n",
    "    return M \\ rhs\n",
    "end\n",
    "\n",
    "function calculate_bilinear_map!(out::AbstractVector , rhs::AbstractVector, a::AbstractVector, b::AbstractVector, cellvalues::CellValues, dh::DofHandler, M_cholesky)\n",
    "    n = ndofs(dh)\n",
    "    fill!(rhs,0.0)\n",
    "    n_basefuncs = getnbasefunctions(cellvalues)\n",
    "    qpoints = getnquadpoints(cellvalues)\n",
    "    re = zeros(n_basefuncs)\n",
    "    \n",
    "    for cell in CellIterator(dh)\n",
    "        dofs = celldofs(cell)\n",
    "        reinit!(cellvalues, cell)\n",
    "        fill!(re, 0.0)\n",
    "        \n",
    "        ae = a[dofs]\n",
    "        be = b[dofs]\n",
    "        \n",
    "        for q in 1:qpoints\n",
    "            dΩ = getdetJdV(cellvalues, q)\n",
    "            \n",
    "            ∇a_q = zero(Vec{2,Float64})\n",
    "            ∇b_q = zero(Vec{2,Float64})\n",
    "            \n",
    "            for j in 1:n_basefuncs\n",
    "                ∇ϕⱼ = shape_gradient(cellvalues, q, j)\n",
    "                ∇a_q += ae[j] * ∇ϕⱼ\n",
    "                ∇b_q += be[j] * ∇ϕⱼ\n",
    "            end\n",
    "            \n",
    "            grad_dot_product = ∇a_q ⋅ ∇b_q\n",
    "            \n",
    "            for i in 1:n_basefuncs\n",
    "                ϕᵢ = shape_value(cellvalues, q, i)\n",
    "                re[i] += grad_dot_product * ϕᵢ * dΩ\n",
    "            end\n",
    "        end\n",
    "        assemble!(rhs, dofs, re)\n",
    "    end\n",
    "    \n",
    "    out = M \\ rhs\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df3130",
   "metadata": {},
   "source": [
    "Here we define which metric we want to use:\n",
    "In our case we will stick with the squared $L^2$ metric, but in theory one would receive more stable EIT reconstruction if instead one calculates Wasserstein distance, Spectral distances or similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52b02f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mUsing fallback BLAS replacements for ([\"dasum_64_\"]), performance may be degraded\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Enzyme.Compiler ~/.julia/packages/Enzyme/sQTaL/src/compiler.jl:4430\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Here we define the metric we will use:\n",
    "d = (x,y) -> norm(x-y)^2\n",
    "∂d = (x,y) -> 2*(x-y) \n",
    "# This allows us to plugin other metrics and differentiate with Enzyme:\n",
    "# define metric here:\n",
    "\n",
    "# define metric here:\n",
    "#d = (x, y) -> ...\n",
    "using Enzyme\n",
    "∂ₓd(x, y) = Enzyme.gradient(Reverse, Const(d), x, y)[1] \n",
    "# We don't use Enzyme Autodiff, because the metric is sufficiently simple.\n",
    "a = randn(10)\n",
    "b = randn(10)\n",
    "@assert norm(∂d(a,b) - ∂ₓd(a,b)) ≈ 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186951d",
   "metadata": {},
   "source": [
    "With the given matrix and projector our we need to optimize for every mode $(f_i,g_i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c6ff8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_adjoint_step_initial! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function state_adjoint_step!(mode::EITMode, K::AbstractMatrix, M, d,∂d ,down,up,dh::DofHandler, cellvalues::CellValues, maxiter=500)\n",
    "    cg!(mode.u,K, mode.g; maxiter = maxiter)\n",
    "    b = down(mode.u)\n",
    "    mean = Statistics.mean(b) \n",
    "    b .-= mean\n",
    "    mode.u .-= mean \n",
    "    cg!(mode.λ, K, up(∂d(b,mode.f)); maxiter = maxiter)\n",
    "    mode.error = d(b,mode.f)\n",
    "    # add calculation of ∇(u)⋅∇(λ) here once figured out\n",
    "    mode.δσ = calculate_bilinear_map(mode.λ, mode.u, cellvalues, dh, M)    \n",
    "    # Check whether this needs + or - as a sign.\n",
    "end\n",
    "\n",
    "function state_adjoint_step_initial!(mode::EITMode, K_LU, M, d,∂d ,down,up,dh::DofHandler, cellvalues::CellValues)\n",
    "    mode.u = K_LU \\ mode.g\n",
    "    b = down(mode.u)\n",
    "    mean = Statistics.mean(b) \n",
    "    b .-= mean\n",
    "    mode.u .-= mean \n",
    "    mode.λ = K_LU \\ up(∂d(b,mode.f))\n",
    "    mode.error = d(b,mode.f)\n",
    "    # add calculation of ∇(u)⋅∇(λ) here once figured out\n",
    "    mode.δσ = calculate_bilinear_map(mode.λ, mode.u, cellvalues, dh, M)    \n",
    "    # Check whether this needs + or - as a sign.\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee83178",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "#### Tikhonov Regularization\n",
    "For Tikhonov regularization we already have assembled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31646fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sparse([1, 2, 3, 4, 1, 2, 3, 4, 5, 6  …  1054, 1055, 1056, 1087, 1088, 1089, 1055, 1056, 1088, 1089], [1, 1, 1, 1, 2, 2, 2, 2, 2, 2  …  1088, 1088, 1088, 1088, 1088, 1088, 1089, 1089, 1089, 1089], [0.6666666666666664, -0.16666666666666657, -0.3333333333333332, -0.16666666666666657, -0.16666666666666657, 1.3333333333333326, -0.33333333333333326, -0.3333333333333332, -0.1666666666666664, -0.33333333333333326  …  -0.3333333333333333, -0.33333333333333326, -0.3333333333333332, -0.1666666666666666, 1.333333333333333, -0.16666666666666657, -0.3333333333333332, -0.16666666666666657, -0.16666666666666657, 0.6666666666666665], 1089, 1089), SparseArrays.CHOLMOD.Factor{Float64, Int64}\n",
       "type:    LLt\n",
       "method:  simplicial\n",
       "maxnnz:  20895\n",
       "nnz:     20895\n",
       "success: true\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function assemble_K(cellvalues::CellValues, dh::DofHandler)\n",
    "    K = allocate_matrix(dh)\n",
    "    n_basefuncs = getnbasefunctions(cellvalues)\n",
    "    Ke = zeros(n_basefuncs, n_basefuncs)\n",
    "    assembler = start_assemble(K)\n",
    "    for cell in CellIterator(dh)\n",
    "        fill!(Ke, 0)\n",
    "        reinit!(cellvalues, cell)\n",
    "        for q_point in 1:getnquadpoints(cellvalues)\n",
    "            dΩ = getdetJdV(cellvalues, q_point)\n",
    "            for i in 1:n_basefuncs\n",
    "                ∇v = shape_gradient(cellvalues, q_point, i)\n",
    "                for j in 1:n_basefuncs\n",
    "                    ∇u = shape_gradient(cellvalues, q_point, j)\n",
    "                    Ke[i, j] += (∇v ⋅ ∇u) * dΩ\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        assemble!(assembler, celldofs(cell), Ke)\n",
    "    end\n",
    "    return K, cholesky(K)\n",
    "end\n",
    "_ , K_TK = assemble_K(cellvalues, dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17bfa8",
   "metadata": {},
   "source": [
    "#### TV regularization\n",
    "Additinal we need to assemble the TV regularizer. The required Mass matrix we already have asembled and ready to use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fe698d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calc_tv_gradient (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mutable struct TV\n",
    "    δ::AbstractArray # Is supposed to hold the error\n",
    "    rhs::AbstractArray # \n",
    "    err_vec::AbstractArray\n",
    "    error::Float64\n",
    "    total_residual::Float64\n",
    "    total_volume::Float64\n",
    "end\n",
    "function TV(n::Int64)\n",
    "    TV(zeros(n), zeros(n), zeros(n), 0.0, 0.0, 0.0)\n",
    "end\n",
    "\n",
    "function calc_tv_gradient(σ::AbstractVector,tv::TV, cellvalues::CellValues, dh::DofHandler, M, ε::Float64 = 1e-8)\n",
    "    n = ndofs(dh)\n",
    "    rhs = tv.rhs\n",
    "    \n",
    "    n_basefuncs = getnbasefunctions(cellvalues)\n",
    "    qpoints = getnquadpoints(cellvalues)\n",
    "    re = zeros(n_basefuncs)\n",
    "    total_residual = 0.0 # Put into init_tv(...) function\n",
    "    total_volume = 0.0 # Put into init_tv(...) function\n",
    "    for cell in CellIterator(dh)\n",
    "        dofs = celldofs(cell)\n",
    "        reinit!(cellvalues, cell)\n",
    "        fill!(re, 0.0)\n",
    "        ue = σ[dofs]\n",
    "        for q in 1:qpoints\n",
    "            dΩ = getdetJdV(cellvalues, q)\n",
    "            total_volume += dΩ\n",
    "            ∇u_q = zero(Vec{2,Float64})  # assuming 2D\n",
    "            for j in 1:n_basefuncs\n",
    "                ∇ϕⱼ = shape_gradient(cellvalues, q, j)\n",
    "                ∇u_q += ue[j] * ∇ϕⱼ\n",
    "            end\n",
    "            grad_norm_sq = ∇u_q ⋅ ∇u_q + ε^2\n",
    "            grad_norm = sqrt(grad_norm_sq)\n",
    "            ∇u_normalized = ∇u_q / grad_norm\n",
    "            for i in 1:n_basefuncs\n",
    "                ∇ϕᵢ = shape_gradient(cellvalues, q, i)\n",
    "                re[i] += -∇u_normalized ⋅ ∇ϕᵢ * dΩ\n",
    "            end\n",
    "            total_residual += grad_norm * dΩ\n",
    "        end \n",
    "        assemble!(rhs, dofs, re)\n",
    "    end\n",
    "    tv.δ = M \\ rhs\n",
    "    \n",
    "    tv.error = total_residual / total_volume\n",
    "    \n",
    "    return tv.δ, tv.error\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58867593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.00014211640344179044, -0.00018486576361887745, 0.00021187470600005074, -0.00016478845034880395, 0.0003786302204325758, -0.0003455130900355594, -0.00031051581729699086, 0.00039107620269100533, 0.0002953666001322491, -0.00044853071079305917  …  -2.178005776618398e-5, 0.00010370979287720843, -0.0001541848265629342, 9.923186529710191e-5, -0.00030442908176604136, 0.00022535191975102967, -0.000323138138475289, 0.00022995761620118153, -0.00015385376550725737, 0.00021630202062267564], 1.0000000000007197e-8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tv = TV(ndofs(dh))\n",
    "calc_tv_gradient(σ, tv, cellvalues, dh, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9051f0",
   "metadata": {},
   "source": [
    "For finding suitable stepsizes we will use Gauss-Newton.\n",
    "Since we want to avoid implementing a dense Hessian Matrix we use SVD to invert the Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67000b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gauss_newton (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function gauss_newton(J::Matrix{Float64}, r::Vector{Float64}; λ::Float64=1e-3)\n",
    "    U, Σ, V = svd(J, full=false)\n",
    "    n = length(Σ)\n",
    "    Σ_damped = zeros(n)\n",
    "    for i in 1:n\n",
    "        Σ_damped[i] = Σ[i] / (Σ[i]^2 + λ) # Levenberg-Marquardt regularization\n",
    "    end\n",
    "    V * (Σ_damped .* (U' * r))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917dc572",
   "metadata": {},
   "source": [
    "Now that we have all the pieces we can assemble the full optimization step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e857dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_step! (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note: If you want to use truncated SVD as regularization one can pass a smaller number than num_modes\n",
    "function full_step!(M,σ::AbstractVector ,modes::Dict{Int64,EITMode}, num_modes::Int64,tv::TV,  d,∂d ,down,up, dh::DofHandler, cellvalues::CellValues, do_TV::Bool =true, β::Float64 = 1e-5)\n",
    "    # Assemble Matrix: (from vector)\n",
    "    K = assemble_K(cellvalues,dh,σ)\n",
    "    if do_TV\n",
    "        J = zeros(num_modes+1,ndofs(dh))\n",
    "        r = zeros(num_modes+1)\n",
    "        # Launch TV regularizer:\n",
    "        tv_task = Threads.@spawn begin\n",
    "            calc_TV_step!(σ,tv, dh,cellvalues,M)\n",
    "        end\n",
    "    else\n",
    "        J = zeros(num_modes,ndofs(dh))\n",
    "        r = zeros(num_modes)\n",
    "    end\n",
    "    # solve adjoint state method\n",
    "    Threads.@threads for i in 1:num_modes\n",
    "        state_adjoint_step!(mode_dict[i], K, M,  d,∂d , down, up, dh, cellvalues)\n",
    "    end\n",
    "\n",
    "    # Fetch gradients & errors\n",
    "    for i in 1:num_modes\n",
    "        J[i,:] = mode_dict[i].δσ\n",
    "        r[i] = mode_dict[i].error\n",
    "    end\n",
    "    if do_TV\n",
    "        # Fetch TV regularization\n",
    "        fetch(tv_task)\n",
    "        J[num_modes+1,:] = tv.δ\n",
    "        r[num_modes+1] = β * tv.error \n",
    "    end    \n",
    "    # calculate steps with Gauss-Newton\n",
    "    δσ = gauss_newton(J, r, λ=1e-3)\n",
    "    # update σ\n",
    "    σ .-= δσ\n",
    "    σ .= max.(σ ,1e-12) # Ensure positivity\n",
    "    return δσ,r,J\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "020b0e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheat_step! (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note: If you want to use truncated SVD as regularization one can pass a smaller number than num_modes\n",
    "function cheat_step!(M,γ,σ::AbstractVector ,modes::Dict{Int64,EITMode}, num_modes::Int64,tv::TV,  d,∂d ,down,up,dh::DofHandler, cellvalues::CellValues, do_TV::Bool =true, β::Float64 = 1e-5)\n",
    "    # Assemble Matrix: (from vector)\n",
    "    K = assemble_K(cellvalues,dh,σ)\n",
    "    if do_TV\n",
    "        J = zeros(num_modes+1,ndofs(dh))\n",
    "        r = zeros(num_modes+1)\n",
    "        # Launch TV regularizer:\n",
    "        tv_task = Threads.@spawn begin\n",
    "            calc_TV_step!(σ,tv, dh,cellvalues,M)\n",
    "        end\n",
    "    else\n",
    "        J = zeros(num_modes,ndofs(dh))\n",
    "        r = zeros(num_modes)\n",
    "    end\n",
    "    # solve adjoint state method\n",
    "    Threads.@threads for i in 1:num_modes\n",
    "        state_adjoint_step!(mode_dict[i], K, M,  d,∂d ,down,up,dh, cellvalues)\n",
    "    end\n",
    "\n",
    "    # Fetch gradients & errors\n",
    "    for i in 1:num_modes\n",
    "        J[i,:] = mode_dict[i].δσ\n",
    "        r[i] = mode_dict[i].error\n",
    "    end\n",
    "    if do_TV\n",
    "        # Fetch TV regularization\n",
    "        fetch(tv_task)\n",
    "        J[num_modes+1,:] = tv.δ\n",
    "        r[num_modes+1] = β * tv.error \n",
    "    end    \n",
    "    # calculate steps with Gauss-Newton\n",
    "    δσ = gauss_newton(J, r, λ=1e-3)\n",
    "    # update σ\n",
    "    α = - dot(γ-σ, δσ )\n",
    "    σ .-= α*δσ\n",
    "    σ .= max.(σ ,1e-12) # Ensure positivity\n",
    "    return δσ,r,J\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3954fd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_step_initial! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function full_step_initial!(M,σ::AbstractVector ,modes::Dict{Int64,EITMode}, num_modes::Int64,tv::TV,  d,∂d ,down,up, dh::DofHandler, cellvalues::CellValues)\n",
    "    # Assemble Matrix: (from vector)\n",
    "    K = assemble_K(cellvalues,dh,σ)\n",
    "    K_LU = lu(K)\n",
    "    J = zeros(num_modes,ndofs(dh))\n",
    "    r = zeros(num_modes)\n",
    "    # solve adjoint state method\n",
    "    Threads.@threads for i in 1:num_modes\n",
    "        state_adjoint_step!(mode_dict[i], K, M,  d, ∂d ,down , up, dh, cellvalues)\n",
    "    end\n",
    "\n",
    "    # Fetch gradients & errors\n",
    "    for i in 1:num_modes\n",
    "        J[i,:] = mode_dict[i].δσ\n",
    "        r[i] = mode_dict[i].error\n",
    "    end\n",
    "    # calculate steps with Gauss-Newton\n",
    "    δσ = gauss_newton(J, r, λ=1e-3)\n",
    "    # update σ\n",
    "    σ .-=  δσ\n",
    "    σ .= max.(σ ,1e-12) # Ensure positivity\n",
    "    return K,δσ,r,J\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a09d8951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With error: 15.284988831024412\n"
     ]
    }
   ],
   "source": [
    "σ_prev = copy(σ)\n",
    "error  = norm(cond_vec - σ)\n",
    "println(\"With error: \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0b5dd",
   "metadata": {},
   "source": [
    "Let's run this optimization loop a few times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19c54cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3.990094438 seconds, Bytes: 875853408, GC time: 0.234678608, Memory allocations: Base.GC_Diff(875853408, 22168, 2, 13171613, 118, 22548, 234678608, 10, 0)\n"
     ]
    }
   ],
   "source": [
    "result, ftime, bytes, gctime, memallocs = @timed begin\n",
    " _ ,δσ =  full_step_initial!(MC, σ, mode_dict, num_modes, tv,  d,∂d ,down,up,dh, cellvalues)\n",
    "end\n",
    "println(\"Time: \", ftime, \" seconds, Bytes: \", bytes, \", GC time: \", gctime, \", Memory allocations: \", memallocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77e4e15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.938296609410266"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dot(cond_vec-σ_prev, δσ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59287d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With error: 29.39677800990262\n"
     ]
    }
   ],
   "source": [
    "error  = norm(cond_vec - σ)\n",
    "println(\"With error: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2df26d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 "
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching full_step!(::SparseArrays.CHOLMOD.Factor{Float64, Int64}, ::Vector{Float64}, ::Dict{Int64, EITMode}, ::Int64, ::TV, ::DofHandler{2, Grid{2, Quadrilateral, Float64}}, ::CellValues{Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}, Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}, QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}, Vector{Float64}}, ::Bool)\nThe function `full_step!` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  full_step!(::Any, ::AbstractVector, ::Dict{Int64, EITMode}, ::Int64, ::TV, ::Any, ::Any, ::Any, !Matched::Any, !Matched::DofHandler, !Matched::CellValues, !Matched::Bool, !Matched::Float64)\n   @ Main ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y110sZmlsZQ==.jl:2\n  full_step!(::Any, ::AbstractVector, ::Dict{Int64, EITMode}, ::Int64, ::TV, ::Any, ::Any, ::Any, !Matched::Any, !Matched::DofHandler, !Matched::CellValues, !Matched::Bool)\n   @ Main ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y110sZmlsZQ==.jl:2\n  full_step!(::Any, ::AbstractVector, ::Dict{Int64, EITMode}, ::Int64, ::TV, ::Any, ::Any, ::Any, !Matched::Any, !Matched::DofHandler, !Matched::CellValues)\n   @ Main ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y110sZmlsZQ==.jl:2\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching full_step!(::SparseArrays.CHOLMOD.Factor{Float64, Int64}, ::Vector{Float64}, ::Dict{Int64, EITMode}, ::Int64, ::TV, ::DofHandler{2, Grid{2, Quadrilateral, Float64}}, ::CellValues{Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}, Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}, QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}, Vector{Float64}}, ::Bool)\n",
      "The function `full_step!` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "Closest candidates are:\n",
      "  full_step!(::Any, ::AbstractVector, ::Dict{Int64, EITMode}, ::Int64, ::TV, ::Any, ::Any, ::Any, !Matched::Any, !Matched::DofHandler, !Matched::CellValues, !Matched::Bool, !Matched::Float64)\n",
      "   @ Main ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y110sZmlsZQ==.jl:2\n",
      "  full_step!(::Any, ::AbstractVector, ::Dict{Int64, EITMode}, ::Int64, ::TV, ::Any, ::Any, ::Any, !Matched::Any, !Matched::DofHandler, !Matched::CellValues, !Matched::Bool)\n",
      "   @ Main ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y110sZmlsZQ==.jl:2\n",
      "  full_step!(::Any, ::AbstractVector, ::Dict{Int64, EITMode}, ::Int64, ::TV, ::Any, ::Any, ::Any, !Matched::Any, !Matched::DofHandler, !Matched::CellValues)\n",
      "   @ Main ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y110sZmlsZQ==.jl:2\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] macro expansion\n",
      "   @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y121sZmlsZQ==.jl:5 [inlined]\n",
      " [2] macro expansion\n",
      "   @ ./timing.jl:581 [inlined]\n",
      " [3] top-level scope\n",
      "   @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y121sZmlsZQ==.jl:4"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in 1:2000\n",
    "    print(\"Step \", i, \" \")\n",
    "    result, time, bytes, gctime, memallocs = @timed begin\n",
    "        δσ, _ = full_step!(MC, σ, mode_dict, 10, tv, dh, cellvalues, false)\n",
    "        #δσ, _ = cheat_step!(MC, cond_vec, σ, mode_dict, 10, tv,  d,∂d ,down,up,dh, cellvalues, false)\n",
    "    end\n",
    "    #println(\"Time: \", time, \" seconds, Bytes: \", bytes, \", GC time: \", gctime, \", Memory allocations: \", memallocs)\n",
    "    error  = norm(cond_vec - σ)\n",
    "    println(\"With error: \", error)\n",
    "    print(typeof(δσ))\n",
    "    step_param = dot((σ_prev - cond_vec), δσ )\n",
    "    σ_prev = σ\n",
    "    println(\"And ideal step length: \",step_param)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "335da832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089-element Vector{Float64}:\n",
       " 1.1371099337904045\n",
       " 1.2378658403975749\n",
       " 1.3176091271341923\n",
       " 1.2157834973451453\n",
       " 1.1584735563690787\n",
       " 1.036556340237251\n",
       " 1.1918300829211455\n",
       " 1.777472584121229\n",
       " 1.1853086229726397\n",
       " 1.6252572380958648\n",
       " ⋮\n",
       " 1.0941811661948273\n",
       " 1.0905935965188838\n",
       " 1.0753713641162475\n",
       " 1.0889145347750786\n",
       " 1.0837795980966194\n",
       " 1.0874897751987713\n",
       " 1.07521167637571\n",
       " 1.0921922233028767\n",
       " 1.0421980148154175"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#mode_dict[1].δσ\n",
    "σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9df9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#σ,δσ,r = full_step!(MC, σ, mode_dict, num_modes, tv, dh, cellvalues, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88120a7f",
   "metadata": {},
   "source": [
    "## Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2fe38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project is to grid and plot with Plots.jl\n",
    "# I wanna use Plots.jl and not Makie.jl or similar because lateron i want to implement a NN on the grid as a regularizer using Lux.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5cdeaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project to dictionary (coordinate,value)\n",
    "#PointEvalHandler(grid, points::AbstractVector{Vec{dim,T}})\n",
    "# Put values from dictionary into Array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627081da",
   "metadata": {},
   "source": [
    "This is our original and final reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afe42f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction and original with Plots.jl here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62aa3d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
