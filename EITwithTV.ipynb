{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a2562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Code/Julia/FerriteStuff/Notebooks/Github/EnvFerrite`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "update_Jr (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"EnvFerrite\")\n",
    "include(\"EITwithTV.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce44614",
   "metadata": {},
   "source": [
    "# Electrical Impedance Tomography with TV Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f621f58",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this example we give a basic implementation of of the real valued Calderon problem relevant to Electrical Impedance Tomography. We will generate data and afterwards solve the inverse problem with a numerical solver and implement TV regularization.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc6c5a",
   "metadata": {},
   "source": [
    "### Forward EIT:\n",
    "Given a conductivity $\\gamma: \\Omega\\subset\\mathbb{R}^2 \\rightarrow \\mathbb{R}_{+}$ our solution $u\\in H^1(\\Omega,\\mathbb{R}^2)$ (2D case) has to confirm to the equation:\n",
    "\n",
    "\n",
    "$$ \\nabla \\cdot(\\gamma\\nabla u) = 0 \\quad \\forall x \\in \\Omega $$\n",
    "\n",
    "For that equation we will choose a set of electrical current patterns \n",
    "\n",
    "$$ g_1, ..., g_n \\in H^{-\\frac{1}{2}}(\\partial \\Omega, \\mathbb{R}) $$\n",
    "\n",
    "such that:  \n",
    "\n",
    "$$ \\int_{\\partial\\Omega}g_i \\, d\\partial\\Omega = 0 $$\n",
    "\n",
    "to inject into the material via Neumann boundary conditions:\n",
    "\n",
    "$$ \\gamma\\frac{\\partial u_i}{\\partial n} =g_i \\quad \\forall x \\in \\partial\\Omega $$\n",
    "\n",
    "In order to get the corresponding voltages \n",
    "$$ f_1, ..., f_n \\in H^{\\frac{1}{2}}(\\partial \\Omega, \\mathbb{R}) $$\n",
    "we will measure the corresponding voltage as:\n",
    "$$ f_i := u_i|_{\\partial\\Omega} $$\n",
    "\n",
    "with those boundary pairs $ (f_1,g_1), ... , (f_n,g_n) $ we now have an approximation of the Dirichlet to Neumann map:\n",
    "$$ \\Lambda_\\gamma: H^{\\frac{1}{2}}(\\partial \\Omega)\\rightarrow H^{-\\frac{1}{2}}(\\partial \\Omega) $$\n",
    "This is called forward EIT since we just approximated the map:\n",
    "$$ \\gamma \\rightarrow  \\Lambda_\\gamma $$\n",
    "\n",
    "However real Electrical Impedance Tomography requires us to solve an **inverse Problem** where we have to reconstruct:\n",
    "$$ \\Lambda_\\gamma \\rightarrow  \\gamma $$\n",
    "for our approximation of $\\Lambda_\\gamma$ given by voltage-current boundary pairs $(f_i,g_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f0406",
   "metadata": {},
   "source": [
    "### Weak formulation\n",
    "Given the strong formulation:\n",
    "$$ \\nabla \\cdot(\\gamma\\nabla u) = 0 \\quad \\text{with Neumann BC:}\\quad \\gamma\\frac{\\partial u}{\\partial n} = g $$\n",
    "\n",
    "The weak formulation is:\n",
    "$$ \\int\\limits_\\Omega \\gamma \\nabla(u)\\cdot\\nabla(v) \\, d \\Omega = \\int\\limits_{\\partial\\Omega} g \\,v \\,d\\partial\\Omega  \\quad \\forall v\\in H^1(\\Omega)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de196c6",
   "metadata": {},
   "source": [
    "### Inverse EIT\n",
    "We will use $\\gamma$ to refer to the true underlying conductivity and $\\sigma$ for our current conductivity guess.\n",
    "We will choose the simplest minimization functional for optimization:\n",
    "$$ J_i(u_i,\\sigma) = \\| f_i- u_i\\|^2_{\\mathcal{L}^2(\\partial\\Omega)} = \\int_{\\partial\\Omega}(f_i-u_i)^2 \\,d\\partial\\Omega $$\n",
    "In theory however we can plug in another metric or pseudo-metric like Wasserstein-distance or Spetral distance as mesure of distance between $f_i$ und $u_i$.\n",
    "Such that our problem becomes:\n",
    "$$ \\underset{\\sigma}{\\min} \\sum\\limits_{i=1}^n J_i(u_i,\\sigma) $$\n",
    "such that:\n",
    "$$ \\nabla u_i\\cdot(\\sigma\\nabla u_i) = 0\\quad  \\text{and Neumann BC}\\quad \\sigma\\frac{\\partial u_i}{\\partial n} = g_i \\quad \\forall i\\in\\{1, ...,n\\}$$\n",
    "Given the problem our lagrangian becomes:\n",
    "$$ \\mathcal{L}(\\sigma, u, \\lambda) = \\sum\\limits_{i=1}^n\\left( J_i(u_i,\\sigma) + \\langle \\lambda_i, \\nabla\\cdot(\\sigma\\nabla u_i) \\rangle_{\\mathcal{L}^2(\\Omega)}   \\right) $$\n",
    "\n",
    "from this we will use [Adjoint state methods](https://en.wikipedia.org/wiki/Adjoint_state_method#General_case) to calculate the gradient.\n",
    "Without stating any of the steps of the derivation we end up with:\n",
    "- State Equation (Variation with $\\delta_\\lambda$)\n",
    "$$ \\nabla \\cdot(\\sigma\\nabla u_i) = 0\\quad  \\text{with Neumann BC}\\quad \\sigma\\frac{\\partial u_i}{\\partial n} = g_i$$\n",
    "\n",
    "- Adjoint Equation (Variation with $\\delta_u$)\n",
    "$$ \\nabla \\cdot(\\sigma\\nabla\\lambda_i) = 0\\quad  \\text{with Neumann BC}\\quad \\sigma\\frac{\\partial \\lambda_i}{\\partial n} = 2(u_i-f_i)$$\n",
    "- Functional Derivative (Variation with $\\delta_\\sigma$)\n",
    "$$ \\delta_i\\sigma = -\\nabla u_i \\cdot \\nabla \\lambda_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a63d6ec",
   "metadata": {},
   "source": [
    "#### Total Variation (TV) regularization\n",
    "for real world examples and numerical stability we have to assume that our system contains some noise, like $f = f_{true} + \\epsilon$. Since the inverse EIT problem is highly ill conditioned we have to consider regularization.\n",
    "\n",
    "\n",
    "Because $|\\nabla\\sigma|^2$ is non-differentiable when $\\nabla\\sigma=0$, we use\n",
    "$$\n",
    "\\mathcal{R}_{TV}(\\sigma) = \\int_\\Omega \\sqrt{|\\nabla\\sigma|^2+\\eta}\\, d\\Omega,\n",
    "$$\n",
    "and the gradient:\n",
    "$$ \\delta_\\sigma\\mathcal{R}= -\\nabla\\cdot \\left(   \\frac{\\nabla\\sigma}{\\sqrt{|\\nabla \\sigma|^2+ \\eta}} \\right) $$\n",
    "with a small $\\eta$ to revent division by zero.\n",
    "This is a $L^2$ projection that requires us to sove the weak form.\n",
    "##### Weak formulation of TV Regularizer:\n",
    "$$ \\int_\\Omega wv \\,d\\Omega = \\int_\\Omega \\frac{\\nabla(\\sigma)}{\\sqrt{|\\nabla\\sigma|^2+\\eta}}\\cdot\\nabla(v)\\, d\\Omega \\quad \\forall v\\in FESpace$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf00a9",
   "metadata": {},
   "source": [
    "### Full reconstruction Algorithm (Conceptual)\n",
    "+ Preallocate Massmatrix M and L^2 projector (Cholesky factorization)\n",
    "+ Start with conductivity guess $\\sigma_0$ (In our case: $\\sigma_0(x) = 1.0$)\n",
    "+ Preallocate & initialize Conjugate Gradient(CG) solver for $u_1, ...,u_n.\\lambda_1,.., \\lambda_n,w$.\n",
    "+ Repeat till tolerance is reached or other stopping condition:\n",
    "    + From $\\sigma_t$ assemble stiffness matrix $K_{\\sigma_t}$\n",
    "    + for all $i = 1, ...,n$ (in parallel)\n",
    "        + Calculate $u_i$ (State equation) as well as the $\\mathcal{L}^2(\\partial\\Omega)$ error: $\\delta u_i$\n",
    "        + Calculate $\\lambda_i$ (Adjoint equation)\n",
    "        + Calculate $\\delta\\sigma_i$ (Functional derivative)\n",
    "    + Calculate TV Regularization gradient and error.\n",
    "    + Update $\\sigma_{t+1} = \\sigma_t +\\beta\\, \\delta_{TV}\\sigma + \\sum_{i=1}^n \\alpha_i\\,\\delta_i\\sigma $ (with Gauss-Newton with Levenberg-Marquardt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b89dc",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "### Preliminaries\n",
    "Obvious Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa44a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Ferrite\n",
    "using SparseArrays\n",
    "using LinearAlgebra\n",
    "using Revise\n",
    "using Interpolations\n",
    "using Plots\n",
    "using Statistics\n",
    "using IterativeSolvers\n",
    "using LinearMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33323b7",
   "metadata": {},
   "source": [
    "For simplicity we will use a quadratic grid with quadrilateral elements. We are using Quadrilaterals for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9a883c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = generate_grid(Quadrilateral, (32, 32));\n",
    "dim = Ferrite.getspatialdim(grid)\n",
    "order = 1\n",
    "\n",
    "\n",
    "ip = Lagrange{RefQuadrilateral, order}()\n",
    "qr = QuadratureRule{RefQuadrilateral}(2)\n",
    "qr_face = FacetQuadratureRule{RefQuadrilateral}(2)\n",
    "cellvalues = CellValues(qr, ip)\n",
    "facetvalues = FacetValues(qr_face, ip)\n",
    "\n",
    "dh = DofHandler(grid)\n",
    "add!(dh, :u, ip)\n",
    "close!(dh)\n",
    "\n",
    "\n",
    "\n",
    "∂Ω = union(getfacetset.((grid,), [\"left\", \"top\", \"right\", \"bottom\"])...)\n",
    "length(∂Ω)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30d783",
   "metadata": {},
   "source": [
    "For later use we will assemble and cholesky decompose the mass matrix once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f950d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sparse([1, 2, 3, 4, 1, 2, 3, 4, 5, 6  …  1054, 1055, 1056, 1087, 1088, 1089, 1055, 1056, 1088, 1089], [1, 1, 1, 1, 2, 2, 2, 2, 2, 2  …  1088, 1088, 1088, 1088, 1088, 1088, 1089, 1089, 1089, 1089], [0.0004340277777777777, 0.00021701388888888885, 0.00010850694444444441, 0.00021701388888888882, 0.00021701388888888885, 0.0008680555555555555, 0.0004340277777777777, 0.00010850694444444441, 0.00021701388888888893, 0.00010850694444444444  …  0.00010850694444444444, 0.0004340277777777777, 0.00010850694444444441, 0.00021701388888888882, 0.0008680555555555553, 0.00021701388888888882, 0.00010850694444444441, 0.00021701388888888882, 0.00021701388888888882, 0.00043402777777777765], 1089, 1089), SparseArrays.CHOLMOD.Factor{Float64, Int64}\n",
       "type:    LLt\n",
       "method:  simplicial\n",
       "maxnnz:  20895\n",
       "nnz:     20895\n",
       "success: true\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is supposed to be: ∫(u*v)dΩ and it's Cholesky decomposition\n",
    "M, MC = assemble_M(cellvalues,dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0369c0",
   "metadata": {},
   "source": [
    "Furthermore we want to know which entries of the force vector correspond to the boundary:\n",
    "We will get:\n",
    "- the count of nonzero entries in the force vector\n",
    "- the position of non zero entries\n",
    "- a function \"up\" to cast a vector of length of boundary dofs into the length of the force vector\n",
    "- a function \"down\" to cast a vector into the length of the dofs of the force vector that lay on the boundary.\n",
    "\n",
    "Note: depending on the grid and the method used this can be more complicated up and down function.\n",
    "I want to from the start take a very modular approach where one can plugin different methods, even Spectral Methods instead of FEM and the Code might be reusable. That is why in some cases up and down wouldn't be a simple function in vector indices but a full blown operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1acc5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nzc,nzpos, down, up = produce_nonzero_positions(facetvalues, dh,∂Ω)\n",
    "@assert nzc == length(∂Ω)  # This is not true in Gridap.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9909e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity check:\n",
    "# I have never questioned the assumption that up∘down == id and down∘up == id. Maybe I should check this.\n",
    "test_vec = [i for i in 1:nzc]\n",
    "@assert down(up(test_vec)) == test_vec\n",
    "@assert up(down(up(test_vec))) == up(test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704c0e9",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724653f",
   "metadata": {},
   "source": [
    "Now we will make up some conductivity. As well as some current patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a32db90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#24 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conductivity  = (x) -> 1.1 + sin(x[1]) * cos(x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5ee93",
   "metadata": {},
   "source": [
    "For later we want to project that function unto Q1 FE space for that we want to assemble the coefficients in the FESpace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741f5446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089-element Vector{Float64}:\n",
       " 0.6450535642159253\n",
       " 0.6641859150714466\n",
       " 0.6226468097664015\n",
       " 0.601690881462597\n",
       " 0.685021948586164\n",
       " 0.645468805231958\n",
       " 0.707477970024696\n",
       " 0.6700651958589253\n",
       " 0.7314669135515499\n",
       " 0.6963406172344299\n",
       " ⋮\n",
       " 1.3592050021692093\n",
       " 1.3883340781632245\n",
       " 1.416337215072183\n",
       " 1.4431050644646248\n",
       " 1.4685330864484494\n",
       " 1.492522029975305\n",
       " 1.5149780514138347\n",
       " 1.5358140849285546\n",
       " 1.5549464357840737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cond_vec = assemble_function_vector(cellvalues, dh, conductivity, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aee32e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089×1089 SparseMatrixCSC{Float64, Int64} with 9409 stored entries:\n",
       "⎡⠻⣦⡸⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎤\n",
       "⎢⠲⢮⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣟⣽⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣟⣽⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣟⣽⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣟⣽⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⠀⠀⎥\n",
       "⎢⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣦⡀⎥\n",
       "⎣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function assembles the stiffness matrix from a given vector.\n",
    "# This is: ∫(γ * ∇(u)⋅∇(v))dΩ \n",
    "K_from_vec = assemble_K(cellvalues, dh,cond_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee77cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseArrays.CHOLMOD.Factor{Float64, Int64}\n",
       "type:    LLt\n",
       "method:  simplicial\n",
       "maxnnz:  20895\n",
       "nnz:     20895\n",
       "success: true\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is matrix assembly on a function. How do I do it if the conductivity is given as a coefficient vector for Q1 FE Space?\n",
    "# This is: ∫(γ * ∇(u)⋅∇(v))d\n",
    "K_true = assemble_K(cellvalues, dh, conductivity)\n",
    "K_true_LU = factorize(K_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb7d5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: (positive semidefinite self adjoint stiffness matrix)\n",
    "@assert K_true == K_true'  # Not true in Gridap.jl\n",
    "if ndofs(dh) < 500\n",
    "    K_dense = Matrix(K_true)\n",
    "    eig_min = minimum(eigvals(K_dense))\n",
    "    @assert eig_min > -1e-14\n",
    "    print(\"Smallest eigenvalue: \", eig_min)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8ad31",
   "metadata": {},
   "source": [
    "Now we generate current patterns: We assume one current source and one current sink. Important is that it sums of to zero.\n",
    "We generate the right hand side force vectors $g_1, ... g_n$ as an Matrix G and calculate $f_1, ..., f_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ba150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128×8128 Matrix{Float64}:\n",
       "  2.28031     2.25774       2.8858     …   0.00896351   0.00471518\n",
       " -0.822377    0.128708      0.503204       0.00896068   0.00471448\n",
       "  0.15127    -0.907189      0.708219       0.00896638   0.0047159\n",
       " -0.102286    0.0801673    -1.03945        0.00895235   0.00471241\n",
       " -0.0645602   0.030441     -0.242412       0.00893867   0.00470901\n",
       " -0.0399858   0.0134256    -0.147098   …   0.00891984   0.00470433\n",
       " -0.0299563   0.00458881   -0.0979698      0.00889602   0.0046984\n",
       " -0.0244935  -0.000326226  -0.074219       0.00886739   0.00469129\n",
       " -0.0212772  -0.00332372   -0.0605148      0.00883415   0.00468302\n",
       " -0.0192336  -0.00526549   -0.0519835      0.0087965    0.00467366\n",
       "  ⋮                                    ⋱               \n",
       " -0.0134128  -0.0109905    -0.0283843      0.0240971    0.00839202\n",
       " -0.013424   -0.0109791    -0.0284286  …   0.0284299    0.00941065\n",
       " -0.0134336  -0.0109693    -0.0284667      0.0352115    0.0109726\n",
       " -0.0134417  -0.0109611    -0.0284985      0.0466772    0.0135594\n",
       " -0.0134482  -0.0109545    -0.0285243      0.0698071    0.0181989\n",
       " -0.0134532  -0.0109494    -0.0285442      0.113926     0.0292619\n",
       " -0.0134568  -0.0109458    -0.0285583  …   0.470987     0.0462862\n",
       " -0.0134589  -0.0109436    -0.0285667     -0.187214     0.353831\n",
       " -0.0134596  -0.0109429    -0.0285695     -1.15553     -0.922032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_modes = Int64((nzc^2-nzc)//2)\n",
    "G_small = zeros(nzc,num_modes)\n",
    "G = zeros(ndofs(dh),num_modes)\n",
    "k = 1\n",
    "for i in 1:(nzc-1)\n",
    "    for j in i+1:nzc\n",
    "        G_small[i,k] = 1.0\n",
    "        G_small[j,k] = -1.0\n",
    "        G[:,k] = up(G_small[:,k])\n",
    "        k += 1\n",
    "    end\n",
    "end\n",
    "F_big = K_true_LU \\ G\n",
    "F = zeros(nzc,num_modes)\n",
    "k = 1\n",
    "for i in 1:(nzc-1)\n",
    "    for j in i+1:nzc\n",
    "        F[:,k] = down(F_big[:,k])\n",
    "        k += 1\n",
    "    end\n",
    "end\n",
    "col_means = mean(F, dims=1)\n",
    "F .-= col_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73781c70",
   "metadata": {},
   "source": [
    "To be realistic we will add some noise:\n",
    "We have to ensure that our noise has mean zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be5718f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_zero_noise (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function mean_zero_noise(n::Int64, σ::Float64)\n",
    "    out = σ * randn(n)\n",
    "    mean = Statistics.mean(out)\n",
    "    out .- mean\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc589a66",
   "metadata": {},
   "source": [
    "To simplify things we can also do SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec45d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the number of modes according to used SVD modes\n",
    "\n",
    "F, Σ, G_small, Λ, num_modes = do_svd(F,G_small)\n",
    "# Apply singular Values:\n",
    "G = zeros(ndofs(dh),num_modes)\n",
    "F_big = copy(G)\n",
    "for i in 1:num_modes\n",
    "    G[:,i] = up(G_small[:,i])\n",
    "    F_big[:,i] = up(F[:,i])\n",
    "end\n",
    "# We can also plot the singular values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd9be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Σ, label = \"singular values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c3a036",
   "metadata": {},
   "source": [
    "now that we have done SVD on the original choice of modes we have \n",
    "- Truncation of SVD modes, thus regularization\n",
    "- Averaging of noise over multiple measurements\n",
    "- Elimination of any unncessary number of nodes we choose before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6dd1a",
   "metadata": {},
   "source": [
    "Here we define a struct where we save and preallocate all the necessary information for the solver step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f965019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of Matrix difference: 8.536307354525758e-6\n",
      "norm of difference of first SVD mode: 11.472224696560371\n"
     ]
    }
   ],
   "source": [
    "# Implement a sanity check if the two matrices assembled from the function and the vector are roughly the same (use relatively coarse ≈ )\n",
    "Matrix_norm = norm(K_from_vec - K_true)\n",
    "println(\"Norm of Matrix difference: \",Matrix_norm)\n",
    "@assert Matrix_norm < 20.0\n",
    "\n",
    "g_test = G[:,1]\n",
    "f_test_true = K_true \\ g_test\n",
    "f_test_vec = K_from_vec \\g_test\n",
    "vector_norm = norm(f_test_true - f_test_vec)\n",
    "println(\"norm of difference of first SVD mode: \" ,vector_norm)\n",
    "@assert vector_norm < 13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "059522f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_dict = Dict{Int64,EITMode}()\n",
    "for i in 1:num_modes\n",
    "    mode_dict[i] = EITMode(G[:,i],F[:,i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c2f19",
   "metadata": {},
   "source": [
    "### Solving EIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cd183",
   "metadata": {},
   "source": [
    "We will now assume a starting conductivity guess $\\sigma_0(x) = 1.0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180dc966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#26 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "σ₀ = (x) -> 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc5166",
   "metadata": {},
   "source": [
    "We would prefer to save $\\sigma$ as a vector for use in FEM and also have a method to export each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "831b2fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089-element Vector{Float64}:\n",
       " 0.9999999999999998\n",
       " 1.0\n",
       " 0.9999999999999996\n",
       " 1.0000000000000002\n",
       " 0.9999999999999989\n",
       " 1.0000000000000007\n",
       " 1.0000000000000002\n",
       " 0.9999999999999992\n",
       " 0.9999999999999996\n",
       " 1.0000000000000009\n",
       " ⋮\n",
       " 1.0\n",
       " 1.0000000000000004\n",
       " 1.0\n",
       " 1.0000000000000009\n",
       " 0.9999999999999997\n",
       " 1.0000000000000007\n",
       " 0.9999999999999998\n",
       " 1.0000000000000002\n",
       " 0.9999999999999997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Project function here: \n",
    "σ = assemble_function_vector(cellvalues,dh, σ₀, MC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37970b5d",
   "metadata": {},
   "source": [
    "A prerequisite is that we can calculate the bilinear map: $\\nabla(u)\\cdot\\nabla(\\lambda)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f9e1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble right-hand side for the projection of ∇(u) ⋅ ∇(λ) onto the FE space.\n",
    "# This computes rhs_i = ∫ (∇u ⋅ ∇λ) ϕ_i dΩ for each test function ϕ_i.\n",
    "# Assuming u and λ are scalar fields in the same FE space.\n",
    "# cellvalues should be CellScalarValues(qr, ip) where qr is QuadratureRule, ip is Interpolation.\n",
    "#function calculate_bilinear_map(a::AbstractVector, b::AbstractVector, cellvalues::CellValues, dh::DofHandler, M_cholesky)\n",
    "# Write some code which demonstrates this function:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df3130",
   "metadata": {},
   "source": [
    "Here we define which metric we want to use:\n",
    "In our case we will stick with the squared $L^2$ metric, but in theory one would receive more stable EIT reconstruction if instead one calculates Wasserstein distance, Spectral distances or similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52b02f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mUsing fallback BLAS replacements for ([\"dasum_64_\"]), performance may be degraded\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Enzyme.Compiler ~/.julia/packages/Enzyme/sQTaL/src/compiler.jl:4430\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Here we define the metric we will use:\n",
    "d = (x,y) -> norm(x-y)^2\n",
    "∂d = (x,y) -> 2*(x-y) \n",
    "# This allows us to plugin other metrics and differentiate with Enzyme:\n",
    "# define metric here:\n",
    "\n",
    "# define other metric here:\n",
    "#d = (x, y) -> ...\n",
    "# We can now use Enzyme or Zygote Autodiff library:\n",
    "using Enzyme\n",
    "makegradₓ(d) = (x, y) -> Enzyme.gradient(Reverse, Const(d), x, y)[1]\n",
    "∂ₓd = makegradₓ(d)\n",
    "# Sanity test, whether this is working:\n",
    "a = randn(10)\n",
    "b = randn(10)\n",
    "@assert norm(∂d(a,b) - ∂ₓd(a,b)) ≈ 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186951d",
   "metadata": {},
   "source": [
    "With the given matrix and projector our we need to solve for every mode $(f_i,g_i)$ the adjoint-state-solution to get the gradient:\n",
    "\n",
    "$$ \\nabla_\\sigma d(K_\\sigma\\; g_i,f_i) $$\n",
    "with $d(\\cdot,\\cdot)$ being some pseudo metric through which we measure the error and $K_\\sigma$ the Forward EIT operator dependent on $\\sigma$\n",
    "Our implementation becomes:\n",
    "```julia\n",
    "function state_adjoint_step!(mode::EITMode, K_factorized, M, d,∂d ,down,up,dh::DofHandler, cellvalues::CellValues)\n",
    "    # We solve the state equation ∇⋅(σ∇uᵢ) = 0 : σ∂u/∂𝐧 = g\n",
    "    mode.u = K \\ mode.g\n",
    "    # Projection from down:Ω → ∂Ω\n",
    "    b = down(mode.u) \n",
    "    # Normalize: ∫(uᵢ)d∂Ω = 0\n",
    "    mean = Statistics.mean(b) \n",
    "    b .-= mean\n",
    "    mode.u .-= mean \n",
    "    # We solve the adjoint equation ∇⋅(σ∇λᵢ) = 0 : σ∂u/∂𝐧 = ∂ₓd(u,f)\n",
    "    mode.λ = K \\ up(∂d(b,mode.f)) \n",
    "    # Note: we have projection up: ∂Ω → Ω (fill in zeros)\n",
    "    # ∂ₓd is gradient of pseudo metric d(x,y)\n",
    "    mode.error = d(b,mode.f) # Error according to pseudo metric d(x,y)\n",
    "    # Calculate ∇(uᵢ)⋅∇(λᵢ) here: \n",
    "    mode.δσ = calculate_bilinear_map(mode.λ, mode.u, cellvalues, dh, M) \n",
    "end\n",
    "```\n",
    "For efficiency we will use a Conjugate Gradient (CG) solver in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd0183b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#36 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For comparison to adjoint-state-method implement gradient based on Autodiff here:\n",
    "# we need to define assemble an optimization functional:\n",
    "\n",
    "function assemble_optimization_functional(cellvalues::CellValues,dh::DofHandler,up,down,d)\n",
    "    return (σ,f,g) -> begin\n",
    "        K = assemble_K(cellvalues,dh,σ,1e-12)\n",
    "        # enforce main zero\n",
    "        f .-= Statistics.mean(f)\n",
    "        b = up(g)\n",
    "        b .-= Statistics.mean(b)\n",
    "        u = down(K \\ b)  # This is the problematic part for using Autodiff\n",
    "        #maybe enforce main zero again:\n",
    "        error = d(u,f)\n",
    "        return error\n",
    "    end\n",
    "end\n",
    "J_func = assemble_optimization_functional(cellvalues,dh,up,down,d)\n",
    "\n",
    "# now in the next step we need to use autodiff:\n",
    "\n",
    "makegrad_σ(J) = (σ, f, g) -> Enzyme.gradient(Reverse, Const(J), σ, f, g)[1]\n",
    "\n",
    "∂σJ = makegrad_σ(J_func)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ebfc8",
   "metadata": {},
   "source": [
    "Thus we have assembled the gradient for a mode using Enzyme Autodiff: \n",
    "Let's try whether it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0776d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't try for now\n",
    "#∂σJ(σ, mode_dict[1].f, down(mode_dict[1].g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f532fc",
   "metadata": {},
   "source": [
    "No it doesn't\n",
    "\n",
    "It get's a little bit more complicated than I thought and I already asked in the forum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee83178",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "#### Tikhonov Regularization\n",
    "For Tikhonov regularization we already have assembled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31646fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sparse([1, 2, 3, 4, 1, 2, 3, 4, 5, 6  …  1054, 1055, 1056, 1087, 1088, 1089, 1055, 1056, 1088, 1089], [1, 1, 1, 1, 2, 2, 2, 2, 2, 2  …  1088, 1088, 1088, 1088, 1088, 1088, 1089, 1089, 1089, 1089], [0.6666666666666664, -0.16666666666666657, -0.3333333333333332, -0.16666666666666657, -0.16666666666666657, 1.3333333333333326, -0.33333333333333326, -0.3333333333333332, -0.1666666666666664, -0.33333333333333326  …  -0.3333333333333333, -0.33333333333333326, -0.3333333333333332, -0.1666666666666666, 1.333333333333333, -0.16666666666666657, -0.3333333333333332, -0.16666666666666657, -0.16666666666666657, 0.6666666666666665], 1089, 1089), SparseArrays.CHOLMOD.Factor{Float64, Int64}\n",
       "type:    LLt\n",
       "method:  simplicial\n",
       "maxnnz:  20895\n",
       "nnz:     20895\n",
       "success: true\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is: ∫(∇(u)⋅∇(v))dΩ the stiffness matrix without specified coefficients. It is used for Tikhonov H¹ regularization. \n",
    "K_st , K_TK = assemble_K(cellvalues, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e57ed55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FerriteEITProblem(sparse([1, 2, 3, 4, 1, 2, 3, 4, 5, 6  …  1054, 1055, 1056, 1087, 1088, 1089, 1055, 1056, 1088, 1089], [1, 1, 1, 1, 2, 2, 2, 2, 2, 2  …  1088, 1088, 1088, 1088, 1088, 1088, 1089, 1089, 1089, 1089], [0.0004340277777777777, 0.00021701388888888885, 0.00010850694444444441, 0.00021701388888888882, 0.00021701388888888885, 0.0008680555555555555, 0.0004340277777777777, 0.00010850694444444441, 0.00021701388888888893, 0.00010850694444444444  …  0.00010850694444444444, 0.0004340277777777777, 0.00010850694444444441, 0.00021701388888888882, 0.0008680555555555553, 0.00021701388888888882, 0.00010850694444444441, 0.00021701388888888882, 0.00021701388888888882, 0.00043402777777777765], 1089, 1089), SparseArrays.CHOLMOD.Factor{Float64, Int64}\n",
       "type:    LLt\n",
       "method:  simplicial\n",
       "maxnnz:  20895\n",
       "nnz:     20895\n",
       "success: true\n",
       ", sparse([1, 2, 3, 4, 1, 2, 3, 4, 5, 6  …  1054, 1055, 1056, 1087, 1088, 1089, 1055, 1056, 1088, 1089], [1, 1, 1, 1, 2, 2, 2, 2, 2, 2  …  1088, 1088, 1088, 1088, 1088, 1088, 1089, 1089, 1089, 1089], [0.6666666666666664, -0.16666666666666657, -0.3333333333333332, -0.16666666666666657, -0.16666666666666657, 1.3333333333333326, -0.33333333333333326, -0.3333333333333332, -0.1666666666666664, -0.33333333333333326  …  -0.3333333333333333, -0.33333333333333326, -0.3333333333333332, -0.1666666666666666, 1.333333333333333, -0.16666666666666657, -0.3333333333333332, -0.16666666666666657, -0.16666666666666657, 0.6666666666666665], 1089, 1089), var\"#15#21\"{Vector{Int64}}(Core.Box([-2.5537374137331925e-13, -1.1093171972209962e-12, 0.0, -1.0914875541661865e-12, -2.6506003783032394e-12, 0.0, -4.224333183245718e-12, 0.0, -5.933966936951602e-12, 0.0  …  -6.889685219765703e-10, 2.289416359021481e-9, -1.7195269887886742e-8, 6.874829704537862e-8, -2.1113497881819464e-7, 3.4794794324508474e-7, 2.2525135513586618e-7, -3.4820507752854776e-6, 8.820538434257722e-6, 9.589912735275032e-7]), [1, 2, 4, 5, 7, 9, 11, 13, 15, 17  …  1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089]), var\"#14#20\"{Vector{Int64}}([1, 2, 4, 5, 7, 9, 11, 13, 15, 17  …  1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089]), var\"#28#29\"(), var\"#30#31\"(), [0.9999999999999998, 1.0, 0.9999999999999996, 1.0000000000000002, 0.9999999999999989, 1.0000000000000007, 1.0000000000000002, 0.9999999999999992, 0.9999999999999996, 1.0000000000000009  …  1.0, 1.0, 1.0000000000000004, 1.0, 1.0000000000000009, 0.9999999999999997, 1.0000000000000007, 0.9999999999999998, 1.0000000000000002, 0.9999999999999997], sparse([1, 2, 3, 4, 1, 2, 3, 4, 5, 6  …  1054, 1055, 1056, 1087, 1088, 1089, 1055, 1056, 1088, 1089], [1, 1, 1, 1, 2, 2, 2, 2, 2, 2  …  1088, 1088, 1088, 1088, 1088, 1088, 1089, 1089, 1089, 1089], [0.6666666666666664, -0.16666666666666657, -0.33333333333333315, -0.16666666666666657, -0.16666666666666657, 1.3333333333333324, -0.33333333333333326, -0.33333333333333315, -0.16666666666666632, -0.33333333333333315  …  -0.33333333333333337, -0.33333333333333326, -0.33333333333333326, -0.16666666666666663, 1.333333333333333, -0.16666666666666657, -0.33333333333333326, -0.16666666666666663, -0.16666666666666657, 0.6666666666666665], 1089, 1089), SparseArrays.CHOLMOD.Factor{Float64, Int64}\n",
       "type:    LLt\n",
       "method:  simplicial\n",
       "maxnnz:  20895\n",
       "nnz:     20895\n",
       "success: true\n",
       ", CellValues{Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}, Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}, QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}, Vector{Float64}}(Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}(Lagrange{RefQuadrilateral, 1}(), [0.6220084679281462 0.16666666666666669 0.16666666666666669 0.044658198738520456; 0.16666666666666669 0.6220084679281462 0.044658198738520456 0.16666666666666669; 0.044658198738520456 0.16666666666666669 0.16666666666666669 0.6220084679281462; 0.16666666666666669 0.044658198738520456 0.6220084679281462 0.16666666666666669], [0.6220084679281462 0.16666666666666669 0.16666666666666669 0.044658198738520456; 0.16666666666666669 0.6220084679281462 0.044658198738520456 0.16666666666666669; 0.044658198738520456 0.16666666666666669 0.16666666666666669 0.6220084679281462; 0.16666666666666669 0.044658198738520456 0.6220084679281462 0.16666666666666669], Vec{2, Float64}[[-12.618802153517006, -12.618802153517006] [-12.618802153517006, -3.381197846482994] [-3.381197846482994, -12.618802153517006] [-3.381197846482994, -3.381197846482994]; [12.618802153517006, -3.381197846482994] [12.618802153517006, -12.618802153517006] [3.381197846482994, -3.381197846482994] [3.381197846482994, -12.618802153517006]; [3.381197846482994, 3.381197846482994] [3.381197846482994, 12.618802153517006] [12.618802153517006, 3.381197846482994] [12.618802153517006, 12.618802153517006]; [-3.381197846482994, 12.618802153517006] [-3.381197846482994, 3.381197846482994] [-12.618802153517006, 12.618802153517006] [-12.618802153517006, 3.381197846482994]], Vec{2, Float64}[[-0.39433756729740643, -0.39433756729740643] [-0.39433756729740643, -0.10566243270259357] [-0.10566243270259357, -0.39433756729740643] [-0.10566243270259357, -0.10566243270259357]; [0.39433756729740643, -0.10566243270259357] [0.39433756729740643, -0.39433756729740643] [0.10566243270259357, -0.10566243270259357] [0.10566243270259357, -0.39433756729740643]; [0.10566243270259357, 0.10566243270259357] [0.10566243270259357, 0.39433756729740643] [0.39433756729740643, 0.10566243270259357] [0.39433756729740643, 0.39433756729740643]; [-0.10566243270259357, 0.39433756729740643] [-0.10566243270259357, 0.10566243270259357] [-0.39433756729740643, 0.39433756729740643] [-0.39433756729740643, 0.10566243270259357]], nothing, nothing), Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}(Lagrange{RefQuadrilateral, 1}(), [0.6220084679281462 0.16666666666666669 0.16666666666666669 0.044658198738520456; 0.16666666666666669 0.6220084679281462 0.044658198738520456 0.16666666666666669; 0.044658198738520456 0.16666666666666669 0.16666666666666669 0.6220084679281462; 0.16666666666666669 0.044658198738520456 0.6220084679281462 0.16666666666666669], Vec{2, Float64}[[-0.39433756729740643, -0.39433756729740643] [-0.39433756729740643, -0.10566243270259357] [-0.10566243270259357, -0.39433756729740643] [-0.10566243270259357, -0.10566243270259357]; [0.39433756729740643, -0.10566243270259357] [0.39433756729740643, -0.39433756729740643] [0.10566243270259357, -0.10566243270259357] [0.10566243270259357, -0.39433756729740643]; [0.10566243270259357, 0.10566243270259357] [0.10566243270259357, 0.39433756729740643] [0.39433756729740643, 0.10566243270259357] [0.39433756729740643, 0.39433756729740643]; [-0.10566243270259357, 0.39433756729740643] [-0.10566243270259357, 0.10566243270259357] [-0.39433756729740643, 0.39433756729740643] [-0.39433756729740643, 0.10566243270259357]], nothing), QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}([0.9999999999999996, 0.9999999999999996, 0.9999999999999996, 0.9999999999999996], Vec{2, Float64}[[-0.5773502691896257, -0.5773502691896257], [0.5773502691896257, -0.5773502691896257], [-0.5773502691896257, 0.5773502691896257], [0.5773502691896257, 0.5773502691896257]]), [0.0009765624999999996, 0.0009765624999999996, 0.0009765624999999996, 0.0009765624999999996]), DofHandler{2, Grid{2, Quadrilateral, Float64}}(SubDofHandler{DofHandler{2, Grid{2, Quadrilateral, Float64}}}[SubDofHandler{DofHandler{2, Grid{2, Quadrilateral, Float64}}}(DofHandler{2, Grid{2, Quadrilateral, Float64}}(#= circular reference @-3 =#), OrderedCollections.OrderedSet{Int64}([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024]), [:u], Interpolation[Lagrange{RefQuadrilateral, 1}()], Int64[], 4)], [:u], [1, 2, 3, 4, 2, 5, 6, 3, 5, 7  …  1087, 1086, 1054, 1055, 1088, 1087, 1055, 1056, 1089, 1088], [1, 5, 9, 13, 17, 21, 25, 29, 33, 37  …  4057, 4061, 4065, 4069, 4073, 4077, 4081, 4085, 4089, 4093], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], true, Grid{2, Quadrilateral, Float64}(Quadrilateral[Quadrilateral((1, 2, 35, 34)), Quadrilateral((2, 3, 36, 35)), Quadrilateral((3, 4, 37, 36)), Quadrilateral((4, 5, 38, 37)), Quadrilateral((5, 6, 39, 38)), Quadrilateral((6, 7, 40, 39)), Quadrilateral((7, 8, 41, 40)), Quadrilateral((8, 9, 42, 41)), Quadrilateral((9, 10, 43, 42)), Quadrilateral((10, 11, 44, 43))  …  Quadrilateral((1046, 1047, 1080, 1079)), Quadrilateral((1047, 1048, 1081, 1080)), Quadrilateral((1048, 1049, 1082, 1081)), Quadrilateral((1049, 1050, 1083, 1082)), Quadrilateral((1050, 1051, 1084, 1083)), Quadrilateral((1051, 1052, 1085, 1084)), Quadrilateral((1052, 1053, 1086, 1085)), Quadrilateral((1053, 1054, 1087, 1086)), Quadrilateral((1054, 1055, 1088, 1087)), Quadrilateral((1055, 1056, 1089, 1088))], Node{2, Float64}[Node{2, Float64}([-1.0, -1.0]), Node{2, Float64}([-0.9375, -1.0]), Node{2, Float64}([-0.875, -1.0]), Node{2, Float64}([-0.8125, -1.0]), Node{2, Float64}([-0.75, -1.0]), Node{2, Float64}([-0.6875, -1.0]), Node{2, Float64}([-0.625, -1.0]), Node{2, Float64}([-0.5625, -1.0]), Node{2, Float64}([-0.5, -1.0]), Node{2, Float64}([-0.4375, -1.0])  …  Node{2, Float64}([0.4375, 1.0]), Node{2, Float64}([0.5, 1.0]), Node{2, Float64}([0.5625, 1.0]), Node{2, Float64}([0.625, 1.0]), Node{2, Float64}([0.6875, 1.0]), Node{2, Float64}([0.75, 1.0]), Node{2, Float64}([0.8125, 1.0]), Node{2, Float64}([0.875, 1.0]), Node{2, Float64}([0.9375, 1.0]), Node{2, Float64}([1.0, 1.0])], Dict{String, OrderedCollections.OrderedSet{Int64}}(), Dict{String, OrderedCollections.OrderedSet{Int64}}(), Dict{String, OrderedCollections.OrderedSet{FacetIndex}}(\"left\" => OrderedCollections.OrderedSet{FacetIndex}([FacetIndex((1, 4)), FacetIndex((33, 4)), FacetIndex((65, 4)), FacetIndex((97, 4)), FacetIndex((129, 4)), FacetIndex((161, 4)), FacetIndex((193, 4)), FacetIndex((225, 4)), FacetIndex((257, 4)), FacetIndex((289, 4))  …  FacetIndex((705, 4)), FacetIndex((737, 4)), FacetIndex((769, 4)), FacetIndex((801, 4)), FacetIndex((833, 4)), FacetIndex((865, 4)), FacetIndex((897, 4)), FacetIndex((929, 4)), FacetIndex((961, 4)), FacetIndex((993, 4))]), \"bottom\" => OrderedCollections.OrderedSet{FacetIndex}([FacetIndex((1, 1)), FacetIndex((2, 1)), FacetIndex((3, 1)), FacetIndex((4, 1)), FacetIndex((5, 1)), FacetIndex((6, 1)), FacetIndex((7, 1)), FacetIndex((8, 1)), FacetIndex((9, 1)), FacetIndex((10, 1))  …  FacetIndex((23, 1)), FacetIndex((24, 1)), FacetIndex((25, 1)), FacetIndex((26, 1)), FacetIndex((27, 1)), FacetIndex((28, 1)), FacetIndex((29, 1)), FacetIndex((30, 1)), FacetIndex((31, 1)), FacetIndex((32, 1))]), \"right\" => OrderedCollections.OrderedSet{FacetIndex}([FacetIndex((32, 2)), FacetIndex((64, 2)), FacetIndex((96, 2)), FacetIndex((128, 2)), FacetIndex((160, 2)), FacetIndex((192, 2)), FacetIndex((224, 2)), FacetIndex((256, 2)), FacetIndex((288, 2)), FacetIndex((320, 2))  …  FacetIndex((736, 2)), FacetIndex((768, 2)), FacetIndex((800, 2)), FacetIndex((832, 2)), FacetIndex((864, 2)), FacetIndex((896, 2)), FacetIndex((928, 2)), FacetIndex((960, 2)), FacetIndex((992, 2)), FacetIndex((1024, 2))]), \"top\" => OrderedCollections.OrderedSet{FacetIndex}([FacetIndex((993, 3)), FacetIndex((994, 3)), FacetIndex((995, 3)), FacetIndex((996, 3)), FacetIndex((997, 3)), FacetIndex((998, 3)), FacetIndex((999, 3)), FacetIndex((1000, 3)), FacetIndex((1001, 3)), FacetIndex((1002, 3))  …  FacetIndex((1015, 3)), FacetIndex((1016, 3)), FacetIndex((1017, 3)), FacetIndex((1018, 3)), FacetIndex((1019, 3)), FacetIndex((1020, 3)), FacetIndex((1021, 3)), FacetIndex((1022, 3)), FacetIndex((1023, 3)), FacetIndex((1024, 3))])), Dict{String, OrderedCollections.OrderedSet{VertexIndex}}()), 1089), 1089)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mutable struct FerriteEITProblem\n",
    "    M # Massmatrix ∫(ϕᵢϕⱼ)dΩ as Sparse matrix\n",
    "    MC # Massmatrix Cholesky \n",
    "    KST # Stiffness matrix ∫(∇ϕᵢ⋅∇ϕⱼ)dΩ of the mesh\n",
    "    up # Projection to boundary (Can be an operator)\n",
    "    down # Projection from boundary to force vector\n",
    "    d # the metric we are using for the problem\n",
    "    ∂ₓd # the metric d(x,y) differentiated after x\n",
    "    σ # The current guess of the conductivity\n",
    "    K # The current guess of the stiffnessmatrix ∫(σ*∇ϕᵢ⋅∇ϕⱼ)dΩ assembled from σ\n",
    "    Kfac # factorized version of guess of stiffness matrix\n",
    "    cellvalues::CellValues\n",
    "    dh::DofHandler\n",
    "    n::Int64 # ndofs(dh)\n",
    "end\n",
    "K_σ = assemble_K(cellvalues,dh,σ)\n",
    "\n",
    "data = FerriteEITProblem(M,MC,K_st,up,down, d, ∂d, σ, K_σ, factorize(K_σ),cellvalues,dh,ndofs(dh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17bfa8",
   "metadata": {},
   "source": [
    "#### TV regularization\n",
    "Additinal we need to assemble the TV regularizer. The required Mass matrix we already have asembled and ready to use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58867593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.00014211640344179044, -0.00018486576361887745, 0.00021187470600005074, -0.00016478845034880395, 0.0003786302204325758, -0.0003455130900355594, -0.00031051581729699086, 0.00039107620269100533, 0.0002953666001322491, -0.00044853071079305917  …  -2.178005776618398e-5, 0.00010370979287720843, -0.0001541848265629342, 9.923186529710191e-5, -0.00030442908176604136, 0.00022535191975102967, -0.000323138138475289, 0.00022995761620118153, -0.00015385376550725737, 0.00021630202062267564], 1.0000000000007197e-8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tv = TV(ndofs(dh))\n",
    "calc_tv_gradient!(σ, tv, cellvalues, dh, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9051f0",
   "metadata": {},
   "source": [
    "For finding suitable stepsizes we will use Gauss-Newton.\n",
    "Since we want to avoid implementing a dense Hessian Matrix we use SVD to invert the Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37068654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later I might want to do Split-Bregman\n",
    "\n",
    "#=\n",
    "using LinearAlgebra\n",
    "\n",
    "# Forward operator: F(γ) -> simulated boundary voltages\n",
    "function forward(γ)\n",
    "    # placeholder: replace with your FEM/EIT solver\n",
    "    return γ # dummy\n",
    "end\n",
    "\n",
    "# Residual: r(γ) = F(γ) - y\n",
    "function residual(γ, y)\n",
    "    return forward(γ) - y\n",
    "end\n",
    "\n",
    "# Gradient of data term (Jacobian): ∇_γ 0.5*||F(γ)-y||^2\n",
    "function grad_data(γ, y)\n",
    "    # placeholder: replace with actual Jacobian * residual\n",
    "    return residual(γ, y)\n",
    "end\n",
    "\n",
    "\n",
    "# That are the exact axoims the proximal operator has to fullfill?\n",
    "# Example proximal operator: soft-thresholding (for L1 norm)\n",
    "function prox_l1(x, λ)\n",
    "    return sign.(x) .* max.(abs.(x) .- λ, 0)\n",
    "end\n",
    "\n",
    "# Split Bregman iteration\n",
    "function split_bregman(γ0, y; λ=1.0, μ=1.0, niter=20, prox=prox_l1)\n",
    "    γ = copy(γ0)\n",
    "    d = zeros(size(γ0))\n",
    "    b = zeros(size(γ0))\n",
    "    \n",
    "    for k in 1:niter\n",
    "        # --- Update γ (data term + quadratic penalty) ---\n",
    "        # Solve: min 0.5||F(γ)-y||^2 + μ/2 ||∇γ - d - b||^2\n",
    "        # Here we do a simple gradient descent for illustration\n",
    "        g = grad_data(γ, y) + μ * (γ - d - b) # replace ∇γ with identity for simplicity\n",
    "        γ -= 0.1 * g # step size 0.1, tune for your problem\n",
    "        \n",
    "        # --- Update auxiliary variable d (prox of regularizer) ---\n",
    "        d = prox(γ + b, λ/μ)\n",
    "        \n",
    "        # --- Update Bregman variable ---\n",
    "        b += γ - d\n",
    "    end\n",
    "    \n",
    "    return γ\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a7de0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct OptParam\n",
    "    τ::Float64 # Stepsize for update σ += τ * δσ\n",
    "    maxiter::Int64 # Max iterations for CG solver\n",
    "    ϵ::Float64 # This is K + ϵI to ensure positive definiteness\n",
    "    num_modes::Int64 # number of modes for truncated SVD  \n",
    "    β_LM::Float64 # For Levenberg marquadt optimization\n",
    "    do_TV::Bool # Whether one does TV regularization or not.\n",
    "    β_TV::Float64 # For TV optimization\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e18a9668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptParam(0.1, 500, 0.0, 127, 0.001, false, 0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = OptParam(0.1,500,0.0,num_modes,1e-3,false,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccb33081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gauss_newton_step! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function will not check for mismatches and assume everything is properly initialized:\n",
    "function gauss_newton_step!(data::FerriteEITProblem, modes::Dict{Int64,EITMode}, gn::GaussNewtonState, opt::OptParam)\n",
    "    #=if do_TV\n",
    "        tv_task = Threads.@spawn begin\n",
    "            calc_tv_gradient!(σ,tv, dh,cellvalues,M)\n",
    "        end\n",
    "    end =#\n",
    "    # This is the calculation of the gradient \n",
    "    Threads.@threads for i in 1:num_modes\n",
    "        state_adjoint_step_cg!(mode_dict[i], data.K, data.M,  data.d,data.∂d , data.down, data.up, data.dh, data.cellvalues)\n",
    "    end\n",
    "    # Now we will fetch the TV task:\n",
    "    #=if do_TV\n",
    "        fetch(tv_task) \n",
    "    end =#\n",
    "    for i in 1:num_modes\n",
    "        gn.J[i,:] = modes[i].δσ\n",
    "        gn.r[i] = modes[i].error\n",
    "    end\n",
    "\n",
    "    δσ = gauss_newton_cg(gn,opt.β_LM,opt.maxiter)\n",
    "    # update σ\n",
    "    data.σ .+= opt.τ * gns.δ\n",
    "    σ .= max.(σ ,1e-12) # Ensure positivity\n",
    "    \n",
    "    # Assemble new matrix\n",
    "    data.K = assemble_K()\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917dc572",
   "metadata": {},
   "source": [
    "Now that we have all the pieces we can assemble the full optimization step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e857dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_step_old! (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note: If you want to use truncated SVD as regularization one can pass a smaller number than num_modes\n",
    "function full_step_old!(M,σ::AbstractVector ,modes::Dict{Int64,EITMode}, num_modes::Int64,tv::TV,  d,∂d ,down,up, dh::DofHandler, cellvalues::CellValues, do_TV::Bool =true, β::Float64 = 1e-5)\n",
    "    # Assemble Matrix: (from vector)\n",
    "    K = assemble_K(cellvalues,dh,σ)\n",
    "    if do_TV\n",
    "        J = zeros(num_modes+1,ndofs(dh))\n",
    "        r = zeros(num_modes+1)\n",
    "        # Launch TV regularizer:\n",
    "        tv_task = Threads.@spawn begin\n",
    "            calc_TV_step!(σ,tv, dh,cellvalues,M)\n",
    "        end\n",
    "    else\n",
    "        J = zeros(num_modes,ndofs(dh))\n",
    "        r = zeros(num_modes)\n",
    "    end\n",
    "    # solve adjoint state method\n",
    "    Threads.@threads for i in 1:num_modes\n",
    "        state_adjoint_step!(mode_dict[i], K, M,  d,∂d , down, up, dh, cellvalues)\n",
    "    end\n",
    "\n",
    "    # Fetch gradients & errors\n",
    "    for i in 1:num_modes\n",
    "        J[i,:] = mode_dict[i].δσ\n",
    "        r[i] = mode_dict[i].error\n",
    "    end\n",
    "    if do_TV\n",
    "        # Fetch TV regularization\n",
    "        fetch(tv_task)\n",
    "        J[num_modes+1,:] = tv.δ\n",
    "        r[num_modes+1] = β * tv.error \n",
    "    end    \n",
    "    # calculate steps with Gauss-Newton\n",
    "    δσ = gauss_newton(J, r, λ=1e-3)\n",
    "    # update σ\n",
    "    σ .+= δσ\n",
    "    σ .= max.(σ ,1e-12) # Ensure positivity\n",
    "    return δσ,r,J\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "020b0e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheat_step! (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note: If you want to use truncated SVD as regularization one can pass a smaller number than num_modes\n",
    "function cheat_step!(M,γ,σ::AbstractVector ,modes::Dict{Int64,EITMode}, num_modes::Int64,tv::TV,  d,∂d ,down,up,dh::DofHandler, cellvalues::CellValues, do_TV::Bool =true, β::Float64 = 1e-5)\n",
    "    # Assemble Matrix: (from vector)\n",
    "    K = assemble_K(cellvalues,dh,σ)\n",
    "    if do_TV\n",
    "        J = zeros(num_modes+1,ndofs(dh))\n",
    "        r = zeros(num_modes+1)\n",
    "        # Launch TV regularizer:\n",
    "        tv_task = Threads.@spawn begin\n",
    "            calc_TV_step!(σ,tv, dh,cellvalues,M)\n",
    "        end\n",
    "    else\n",
    "        J = zeros(num_modes,ndofs(dh))\n",
    "        r = zeros(num_modes)\n",
    "    end\n",
    "    # solve adjoint state method\n",
    "    Threads.@threads for i in 1:num_modes\n",
    "        state_adjoint_step!(mode_dict[i], K, M,  d,∂d ,down,up,dh, cellvalues)\n",
    "    end\n",
    "\n",
    "    # Fetch gradients & errors\n",
    "    for i in 1:num_modes\n",
    "        J[i,:] = mode_dict[i].δσ\n",
    "        r[i] = mode_dict[i].error\n",
    "    end\n",
    "    if do_TV\n",
    "        # Fetch TV regularization\n",
    "        fetch(tv_task)\n",
    "        J[num_modes+1,:] = tv.δ\n",
    "        r[num_modes+1] = β * tv.error \n",
    "    end    \n",
    "    # calculate steps with Gauss-Newton\n",
    "    δσ = gauss_newton(J, r, λ=1e-3)\n",
    "    # update σ\n",
    "    α = - dot(γ-σ, δσ )\n",
    "    σ .-= α*δσ\n",
    "    σ .= max.(σ ,1e-12) # Ensure positivity\n",
    "    return δσ,r,J\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3954fd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_step_initial! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function full_step_initial!(M,σ::AbstractVector ,modes::Dict{Int64,EITMode}, num_modes::Int64,tv::TV,  d,∂d ,down,up, dh::DofHandler, cellvalues::CellValues)\n",
    "    # Assemble Matrix: (from vector)\n",
    "    K = assemble_K(cellvalues,dh,σ)\n",
    "    K_LU = lu(K)\n",
    "    J = zeros(num_modes,ndofs(dh))\n",
    "    r = zeros(num_modes)\n",
    "    # solve adjoint state method\n",
    "    Threads.@threads for i in 1:num_modes\n",
    "        state_adjoint_step!(mode_dict[i], K, M,  d, ∂d ,down , up, dh, cellvalues)\n",
    "    end\n",
    "\n",
    "    # Fetch gradients & errors\n",
    "    for i in 1:num_modes\n",
    "        J[i,:] = mode_dict[i].δσ\n",
    "        r[i] = mode_dict[i].error\n",
    "    end\n",
    "    # calculate steps with Gauss-Newton\n",
    "    δσ = gauss_newton(J, r, λ=1e-3)\n",
    "    # update σ\n",
    "    σ .+=  δσ\n",
    "    σ .= max.(σ ,1e-12) # Ensure positivity\n",
    "    return K,δσ,r,J\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a09d8951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With error: 15.284988831024412\n"
     ]
    }
   ],
   "source": [
    "σ_prev = copy(σ)\n",
    "error  = norm(cond_vec - σ)\n",
    "println(\"With error: \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0b5dd",
   "metadata": {},
   "source": [
    "Let's run this optimization loop a few times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19c54cea",
   "metadata": {},
   "outputs": [
    {
     "ename": "CompositeException",
     "evalue": "TaskFailedException\n\n    nested task error: UndefVarError: `state_adjoint_step!` not defined in `Main`\n    Suggestion: check for spelling errors or missing imports.\n    Stacktrace:\n     [1] macro expansion\n       @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y113sZmlsZQ==.jl:9 [inlined]\n     [2] (::var\"#153#threadsfor_fun#52\"{var\"#153#threadsfor_fun#51#53\"{SparseArrays.CHOLMOD.Factor{Float64, Int64}, var\"#28#29\", var\"#30#31\", var\"#14#20\"{Vector{Int64}}, var\"#15#21\"{Vector{Int64}}, DofHandler{2, Grid{2, Quadrilateral, Float64}}, CellValues{Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}, Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}, QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}, Vector{Float64}}, SparseMatrixCSC{Float64, Int64}, UnitRange{Int64}}})(tid::Int64; onethread::Bool)\n       @ Main ./threadingconstructs.jl:253\n     [3] #153#threadsfor_fun\n       @ ./threadingconstructs.jl:220 [inlined]\n     [4] (::Base.Threads.var\"#1#2\"{var\"#153#threadsfor_fun#52\"{var\"#153#threadsfor_fun#51#53\"{SparseArrays.CHOLMOD.Factor{Float64, Int64}, var\"#28#29\", var\"#30#31\", var\"#14#20\"{Vector{Int64}}, var\"#15#21\"{Vector{Int64}}, DofHandler{2, Grid{2, Quadrilateral, Float64}}, CellValues{Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}, Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}, QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}, Vector{Float64}}, SparseMatrixCSC{Float64, Int64}, UnitRange{Int64}}}, Int64})()\n       @ Base.Threads ./threadingconstructs.jl:154",
     "output_type": "error",
     "traceback": [
      "TaskFailedException\n",
      "\n",
      "    nested task error: UndefVarError: `state_adjoint_step!` not defined in `Main`\n",
      "    Suggestion: check for spelling errors or missing imports.\n",
      "    Stacktrace:\n",
      "     [1] macro expansion\n",
      "       @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y113sZmlsZQ==.jl:9 [inlined]\n",
      "     [2] (::var\"#153#threadsfor_fun#52\"{var\"#153#threadsfor_fun#51#53\"{SparseArrays.CHOLMOD.Factor{Float64, Int64}, var\"#28#29\", var\"#30#31\", var\"#14#20\"{Vector{Int64}}, var\"#15#21\"{Vector{Int64}}, DofHandler{2, Grid{2, Quadrilateral, Float64}}, CellValues{Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}, Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}, QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}, Vector{Float64}}, SparseMatrixCSC{Float64, Int64}, UnitRange{Int64}}})(tid::Int64; onethread::Bool)\n",
      "       @ Main ./threadingconstructs.jl:253\n",
      "     [3] #153#threadsfor_fun\n",
      "       @ ./threadingconstructs.jl:220 [inlined]\n",
      "     [4] (::Base.Threads.var\"#1#2\"{var\"#153#threadsfor_fun#52\"{var\"#153#threadsfor_fun#51#53\"{SparseArrays.CHOLMOD.Factor{Float64, Int64}, var\"#28#29\", var\"#30#31\", var\"#14#20\"{Vector{Int64}}, var\"#15#21\"{Vector{Int64}}, DofHandler{2, Grid{2, Quadrilateral, Float64}}, CellValues{Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}, Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}, QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}, Vector{Float64}}, SparseMatrixCSC{Float64, Int64}, UnitRange{Int64}}}, Int64})()\n",
      "       @ Base.Threads ./threadingconstructs.jl:154\n",
      "\n",
      "Stacktrace:\n",
      " [1] threading_run(fun::var\"#153#threadsfor_fun#52\"{var\"#153#threadsfor_fun#51#53\"{SparseArrays.CHOLMOD.Factor{Float64, Int64}, var\"#28#29\", var\"#30#31\", var\"#14#20\"{Vector{Int64}}, var\"#15#21\"{Vector{Int64}}, DofHandler{2, Grid{2, Quadrilateral, Float64}}, CellValues{Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}, Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}, QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}, Vector{Float64}}, SparseMatrixCSC{Float64, Int64}, UnitRange{Int64}}}, static::Bool)\n",
      "   @ Base.Threads ./threadingconstructs.jl:173\n",
      " [2] macro expansion\n",
      "   @ ./threadingconstructs.jl:190 [inlined]\n",
      " [3] full_step_initial!(M::SparseArrays.CHOLMOD.Factor{Float64, Int64}, σ::Vector{Float64}, modes::Dict{Int64, EITMode}, num_modes::Int64, tv::TV, d::Function, ∂d::Function, down::Function, up::var\"#15#21\"{Vector{Int64}}, dh::DofHandler{2, Grid{2, Quadrilateral, Float64}}, cellvalues::CellValues{Ferrite.FunctionValues{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Matrix{Vec{2, Float64}}, Nothing, Nothing}, Ferrite.GeometryMapping{1, Lagrange{RefQuadrilateral, 1}, Matrix{Float64}, Matrix{Vec{2, Float64}}, Nothing}, QuadratureRule{RefQuadrilateral, Vector{Float64}, Vector{Vec{2, Float64}}}, Vector{Float64}})\n",
      "   @ Main ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y113sZmlsZQ==.jl:8\n",
      " [4] macro expansion\n",
      "   @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y116sZmlsZQ==.jl:2 [inlined]\n",
      " [5] top-level scope\n",
      "   @ ./timing.jl:581 [inlined]\n",
      " [6] top-level scope\n",
      "   @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y116sZmlsZQ==.jl:0"
     ]
    }
   ],
   "source": [
    "result, ftime, bytes, gctime, memallocs = @timed begin\n",
    " _ ,δσ =  full_step_initial!(MC, σ, mode_dict, num_modes, tv,  d,∂d ,down,up,dh, cellvalues)\n",
    "end\n",
    "println(\"Time: \", ftime, \" seconds, Bytes: \", bytes, \", GC time: \", gctime, \", Memory allocations: \", memallocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4624ae5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `calc_tv_gradient` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `calc_tv_gradient` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y120sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "calc_tv_gradient(σ, tv, cellvalues, dh, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77e4e15e",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `δσ` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `δσ` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y121sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "dot(cond_vec-σ_prev, δσ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59287d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With error: 15.284988831024412\n"
     ]
    }
   ],
   "source": [
    "error  = norm(cond_vec - σ)\n",
    "println(\"With error: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2df26d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 "
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `full_step!` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `full_step!` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] macro expansion\n",
      "   @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y123sZmlsZQ==.jl:5 [inlined]\n",
      " [2] macro expansion\n",
      "   @ ./timing.jl:581 [inlined]\n",
      " [3] top-level scope\n",
      "   @ ~/Code/Julia/FerriteStuff/Notebooks/Github/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y123sZmlsZQ==.jl:4"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in 1:20\n",
    "    print(\"Step \", i, \" \")\n",
    "    result, time, bytes, gctime, memallocs = @timed begin\n",
    "        δσ, _ = full_step!(MC, σ, mode_dict, 10, tv, d,∂d ,down,up,dh, cellvalues, false)\n",
    "        #δσ, _ = cheat_step!(MC, cond_vec, σ, mode_dict, 10, tv,  d,∂d ,down,up,dh, cellvalues, false)\n",
    "    end\n",
    "    #println(\"Time: \", time, \" seconds, Bytes: \", bytes, \", GC time: \", gctime, \", Memory allocations: \", memallocs)\n",
    "    error  = norm(cond_vec - σ)\n",
    "    println(\"With error: \", error)\n",
    "    print(typeof(δσ))\n",
    "    step_param = dot((σ_prev - cond_vec), δσ )\n",
    "    σ_prev = σ\n",
    "    println(\"And ideal step length: \",step_param)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "335da832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089-element Vector{Float64}:\n",
       " 0.9999999999999998\n",
       " 1.0\n",
       " 0.9999999999999996\n",
       " 1.0000000000000002\n",
       " 0.9999999999999989\n",
       " 1.0000000000000007\n",
       " 1.0000000000000002\n",
       " 0.9999999999999992\n",
       " 0.9999999999999996\n",
       " 1.0000000000000009\n",
       " ⋮\n",
       " 1.0\n",
       " 1.0000000000000004\n",
       " 1.0\n",
       " 1.0000000000000009\n",
       " 0.9999999999999997\n",
       " 1.0000000000000007\n",
       " 0.9999999999999998\n",
       " 1.0000000000000002\n",
       " 0.9999999999999997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#mode_dict[1].δσ\n",
    "σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9df9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#σ,δσ,r = full_step!(MC, σ, mode_dict, num_modes, tv, dh, cellvalues, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88120a7f",
   "metadata": {},
   "source": [
    "## Plotting (To be done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2fe38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project is to grid and plot with Plots.jl\n",
    "# I wanna use Plots.jl and not Makie.jl or similar because lateron i want to implement a NN on the grid as a regularizer using Lux.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5cdeaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project to dictionary (coordinate,value)\n",
    "#PointEvalHandler(grid, points::AbstractVector{Vec{dim,T}})\n",
    "# Put values from dictionary into Array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627081da",
   "metadata": {},
   "source": [
    "This is our original and final reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afe42f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction and original with Plots.jl here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62aa3d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
